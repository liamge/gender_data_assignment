<abstract>There are a number of suggested determinants of exam performance that have been put forward by economists and people in other fields of research over the years. For instance Romer suggests class attendance has a significant impact on exam performance, while Siegfried and Strand suggest sex has a significant impact. In this project I shall firstly analyse various factors that affect exam performance using statistical techniques such as means, medians, correlations and such like in question 1 using data from a survey of second year econometrics students. I shall then regress and analyse certain factors in subsequent questions before concluding in question 6 as to my preferred model of exam performance. </abstract><heading>Question 1</heading>Table 1 indicates some descriptive statistics about exam performance. We can see that the mean mark is 64.93%. The range is from a minimum of 9% to a maximum of 95% and the standard deviation is 13.07%. We can also see from graph 1, that the data is slightly negatively skewed, with the median, 65%, above the mean, indicating that there are more higher marks than low ones. However it is approximately normally distributed. To make some comments about these results, we need to break this up into sub-samples. Firstly we can break it up according to sex, as Siegfried and Strand did. For males, table 2 shows that the mean score is 65.4%, which is higher than the corresponding score for females of 63.75%. This agrees with Siegfried and Strand's paper which claims males do better than females. However, the standard deviation for males is lower than for females, 12.64% compared to 14.02%. This indicates greater variation in the data, which may be due to the fact that there are more males than females. We can test whether this is significant difference using the difference in means test as shown in formula 1 appendix 1. Unfortunately, we cannot reject the null that there is no difference at the 10% level, indicating little difference between males and females. We can also break up the samples according to year. Here we find that the highest mean mark is in 2002, at 69.27%. The lowest is in 2001, at 61.71%, with 1999 at 66.85% and 2000 at 62.7%. This is not surprising, given that in 2002, an A level in maths became a prerequisite for straight economics. The standard deviations also vary, being 12.28%, 13.75%, 12.97% and 10.37% for the 1999 to 2002 respectively. This indicates that the variation has decreased over the past 3 years. The range has also changed (i.e. maximum-minimum) as shown in table 3. This may be due to fewer anomalies in certain years, or generally better performance over the four years, as the minimum is highest in 2002 at 45%. <fnote>Siegfried and Strand (1977), "Sex and the Economics student", Review of Economics and Statistics, 247 </fnote><fnote>As the distribution is approximately normally distributed we can use the Central Limit theorem to approximate </fnote>The student's course should also have an impact. For instance a person doing Maths and Economics should in theory get a higher mark in a statistics exam as they are from a mathematical background. Table 4 shows that Maths and Economics students scored the highest on average, although the sample was only 3, so these could be anomalies. The lowest mean mark was for industrial economics, which is slightly surprising given the large amount of mathematical content in the course. However, this may be because the lowest mark in the survey, 9/100 is in this group and this is dragging the average down. Standard deviations also vary considerably across groups from 15.23 in industrial economics, to 9.44 in Economics and Politics. We can also search for other factors that influence exam performance by looking at correlations, cross plots of data sets and correlation. Firstly, we can look at the impact of attendance. Looking at table 4, which shows the cross correlation between a number of variables, we can see that attendance of lectures and classes has a positive linear relationship with exam mark, albeit a small one, while attendance of revision lectures has a nigh on 0 linear relationship with exam score. It is also interesting that lecture and class attendance are positively correlated as well as a number of other explanatory variables; this may become important in the regression as multicollinearity may affect the results subsequently. These results are shown in the cross plots of the 3 explanatory variables with exam score in graphs two to four. The covariance between the variables also indicates the above as shown in table 5, but correlation is a better indicator because it is not affected by the units of variables. In all cases we can see that there is little linear correlation, the highest correlation is 0.65 between lecture and class attendance, perhaps indicating that other factors can explain exam performance better or that a non-linear model may be a better indicator of the relationship. Also looking at table 4, we can see other variables that have an impact upon exam performance, such as number of A-levels and A's at A-level. These two variables have correlations of 0.20 and 0.25 respectively. This is to be expected, since having more A-levels is a good proxy in my view for intelligence, therefore it should improve your mark. In fact the mean number of A-levels was 3.72 and mean number of A's was 3.06. The latter of these results may be an overestimate though; as for some reason someone has 87 As at A-level, which is impossible! However the correlations are only small. This is again shown in graphs 5 and 6, which show cross plots of the two variables with exam mark. Alternative factors that I believe would affect a student's performance are variables such as expenditure on food and alcohol. The mean amount of food and alcohol purchased per week was £33.9 and £26.97, so nearly as much is spent on alcohol as food. Furthermore the minimum value is 0 for both (difficult to believe) and maximum £140 and £150 respectively. I would have thought would have a positive and negative effect respectively. However, according to tables 8 and 9, both have negative correlations and co variances. Perhaps eating less food and less alcohol would therefore lead to better marks. Again however, these correlations are low. On average, the students in the survey spent 16.9, 3.62 and 15.2 hours studying all subjects per week, statistics per week and statistics in the week before the exam respectively. They have large standard deviations at 12.33, 3.46 and 14.54 hours respectively which reflect great variation in the amount of work students undertake. I would also believe that these would have a large positive correlation. In fact looking at table 8 we find that in all cases the linear correlation is small and positive, with the largest positive effect being on the amount of hours spent studying statistics per week at 0.086. Other features of the data that I think are useful are the facts that 51% of the students have parents that work in a maths or economics related field and also the mean number of parents that went to university for a student is 1.04, reflecting that many students have a parent of an academic background. Furthermore, 40.6% of students surveyed went to a sixth form college, 72.2% went to a mixed school, while 52.2% went to a public or fee paying school Also 67% of students are from the UK as opposed to being foreign. <heading>Question 2a</heading><heading>Interpretation of Results</heading>Equation 1 in appendix 2 implies that a 1-unit increase in class attendance (equivalently attending 1% more classes in an academic year) will result in your first year exam mark increasing by 0.17 units (equivalently a 0.17% increase in your mark). The intercept implies that if you attended no classes you would get a mark of 51.27%. Equation 2 implies that attending 1% more classes in an academic year results in your first year exam mark increasing by 0.15%. The intercept implies that if you attended no lectures in the year you would get 53.26%. Equation 3 implies that attending 1% more classes in an academic year results in your first year exam mark increasing by 0.002%. The intercept implies that if you attended no revision lectures in the year you would get 64.97%. <heading>Testing whether attendance matters</heading>Looking at equations 1, 2 and 3 and the corresponding t-tests in appendix 1, we can clearly see that we reject  FORMULA  the highest level of significance, the 0.01% level in all 3 individual cases. This implies that attending 1% more classes, lectures or revision lectures respectively in an academic year does have a significant effect on the mark you get in your end of year statistics exam. <heading>Question 2b</heading><heading>Interpretation of results (equations 4 and 5 appendix 2)</heading>The coefficient on class attendance is 0.15, which implies that holding all other variables constant, if you increase class attendance by 1 unit (1% increase in class attendance in a year), then the exam mark will increase by 0.15 units (0.15% increase in your mark). The coefficient on lecture attendance is 0.06, meaning holding all other variables constant, attending 1% more lectures will increase your mark by 0.06%. The coefficient on revision lecture attendance is slightly surprising, at -0.04, implying that by attending 1% more revision lectures, your mark will decrease by 0.04%. The intercept can be interpreted to mean that if you attended no classes, revision or standard lectures, you would score 49.33% <heading>Tests (shown in appendix 2)</heading>The coefficient on class attendance was significant at the 0.01% level implying that in the multiple regression models, class attendance has a significant impact on test mark. The coefficient on lecture attendance however was not significant, even at the 10% level, implying perhaps that lecture attendance does not have a significant impact in a multivariate framework. However, lecture attendance does appear to have a reasonably high correlation with class attendance, so the regression may be suffering from multicollinearity, which has made the result not significant. However, multicollinearity must be occurring with another factor being 'unhelpful' for it to have a negative impact on the regression. The coefficient on revision lecture attendance was significant up to the 1% level, thus implying that while we can be fairly sure that revision lectures have a significantly negative impact, there is scope for the fact that the null hypothesis is indeed correct (type I error) and that the result is not significant. <fnote>As reported in question 1, the correlation coefficient was 0.67. </fnote>The F-test for the joint explanatory power of the independent variables yielded an F-statistic of 13.07. This is significant at the 0.01% level as it exceeds the critical value of 3.78. Hence we can reject the null hypothesis given in the appendix. This means that the explanatory variables have made a significant joint contribution to exam performance. <heading>Question 3</heading>To investigate whether there are differences in performance between the sub-sample of 2002 students and previous year's students I have created intercept dummy variables and added them to the original equation, as shown by equations 1 and 2 in appendix 3. The first equation is known as the restricted equation, as opposed to the unrestricted model in equation 2, because it imposes the F-test null hypothesis (see hypothesis 4, appendix 3) on equation 2. Hence in equation 2, the intercept is allowed to vary whereas it is not allowed to equation 1 and is assumed to be constant in all years. <heading>Interpretation of coefficients </heading>The intercept in equation 3 can be interpreted as before, meaning that if you attended no lectures and had no A's at A level you would score 56.97. This is slightly nonsensical in the sense that you would not have got onto the course if you did not score any A's at A level. The coefficient of 0.14 on lecture attendance means that if you attended 1% more lectures you would get 0.14 out of 100 more in the exam ceteris peribus. The coefficient of 0.04 on A's scored at A level means that if you get an extra A at A-level you would get 0.04% more ceteris peribus. The dummy variables in this case have a slightly different interpretation. Basically they say how much the intercept will move up or down compared to the omitted category, the year 2000 students. The dummy variable coefficient on 1999 of -1.19 means that if you are a 1999 student, you will score a proportion of 1.19% less than if you are 2002 student. The coefficient of -5.19 on the 2000 dummy variable means that you will score a proportion of 5.19% less than if you were a 2002 student. Finally the coefficient of -6.85 on the 2001 dummy variable means that you will score a proportion of 6.85% less than if you were a 2002 student. These are shown in equations 3 to 6. <heading>Tests</heading>To test whether the additive dummy variables had a significant impact I have evaluated them individually as well as collectively. The results are shown in the tests in appendix 3. The 1999 dummy variable has a highly insignificant result, not even being able to reject the null at the 10% level, indicating that there is no significant difference between 1999 and 2002 scores. The 2000 and 2001 dummy coefficients were significant at the 0.01% level, so in both cases the scores are significantly different from the 2002 scores. The F-test to test whether the dummy variables have significant joint explanatory power yielded a significant result at the 0.01% level. Hence we can reject the null and conclude that the dummies do have significant impact. This is to be expected since two of the three dummies yielded significant results. <fnote>The F-test effectively tests in this case whether there is a significant improvement in fit using the dummy variables. </fnote><heading>Question 4 </heading><heading>Comparison of regressions</heading>Comparing the regressions of mark in first year statistics exam on lecture attendance and A's at A-level for all four years' students as shown by equations 1 to 4 in appendix 4, we find there is some marked differences in the data. If we look at the intercepts we find that the year 2000 has the highest intercept, which can be interpreted as before meaning that if a student attended no lectures and got no A's at A-level, they would score 62.75%. This is to be expected to some extent because in 2002 the university introduced an A-Level maths requirement to get onto single honours economics. In all cases the intercepts are significant. The coefficient on lecture attendance does not vary quite as much, from 0.01 in 2002 to 0.27 in 2001. This coefficient has the same interpretation as it did in question 3. However, I must add that the 2002 and 2000 results are not significant at the 10% and 5% levels respectively as shown by the p-values in the output in question 4, indicating that perhaps in these years lecture attendance did not have a significant impact upon exam performance. The coefficient on A's at A-level also has the same interpretation as in question 3. However, here there are big differences in the coefficients, from 4.9 in 2000 to - 0.11 in 2002. These results are shown in the regression output in appendix 4. However, the 2002, 2001 and 1999 results are not significant at the 10%, 5% and 1% level respectively, perhaps indicating that in these years perhaps other factors that are not in the model are affecting the score. However in 2000 it is significant at the 0.1% level, indicating that conceivably, given that the lecture attendance coefficient was not significant, that As at A-level make up a larger proportion of the explanation of exam performance than in the other years. <heading>Chow test</heading>To test for slope and intercept coefficient constancy we have to use the Chow test for structural change, which is a variant of the F-test, which tests whether there is a significant improvement in fit from splitting the sample into 4 separate sub-samples. The null and alternative hypotheses are shown in the tests in appendix 4. The calculation from the Chow test yields a result of 6.936, which exceeds the critical value of 2.41 at the 0.01% significance level. Therefore we can reject the null and conclude that there is a significant improvement in fit from splitting the sample into 4 sub-samples. <heading>Question 5</heading>In question 3 we were testing that the intercepts are constant, while in question 4 we are testing that all the coefficients, both slope and intercept, are constant. Therefore to test the hypothesis that only the slope coefficients are constant we have to do the opposite of what we were doing in question 3 and in effect test the model we gave in question 3 against question 4. To do this we have to create slope dummy variables, to model the separate regressions for each year as in question 4. This creates the following restricted and unrestricted models. Effectively the restricted model of question 3 is just the unrestricted model of question 4 but with the interactive dummies being set to 0 so the slopes cannot vary. Unrestricted  FORMULA  Restricted  FORMULA  <heading>F-Test</heading>To test for slope coefficient constancy we use the F-test (tests, appendix 5). The null hypotheses being that the slopes are constant and the alternative being that at least one of the coefficients is not equal to the others (see appendix 5). The calculations involve using the RSS from the restricted model and RSS from the unrestricted model (equivalently the sum of RSS from each separate sample for the 4 years) and are shown in appendix 5. We find that the calculated F-test value of 7.29 exceeds the critical value of 2.80. This implies that we reject the null and therefore we find that the slope coefficients are not constant. This is not surprising, seeing as 3 of the 8 slope coefficients gave significant results at the 0.01% level. <heading>Question 6 </heading>Given my results from previous questions and previous research, I am now going to try and formulate a model of exam performance, firstly by trying different variables and then trying various functional forms. The best fitting model should balance off a low residual sum of squares, which is essentially the proportion of the exam mark not explained by the model and a high R², which is the proportion of the variance in exam mark explained by the model. Therefore as a result you should get high and significant t-tests on your individual coefficients and a significant f-test of the joint explanatory power of the model. Romer (1993) claims that class attendance has a significant impact upon exam performance. Class attendance was also significant in this assignment in question 2b, hence I believe it should be included within the model. Another variable I shall include is lecture attendance, which should increase your grasp of the subject and therefore improve your mark, although this is not significant in question 2b (however it is significant in question 3). I shall also include the number of A's at Alevel as this is a good measure of intelligence as well as motivation, which Devadoss and Foltz claim are important. Also I have included how many of the parents attended university, as I think in theory if both parents have gone to university the environment within which the student has worked would be more helpful to develop the student, and will therefore be a more intelligent student. I also included a an intercept dummy to show whether the student has done maths A-level, as this shows aptitude for the subject seeing as the majority of maths A-levels contain some statistics. <fnote>Romer (1993) 'Do students go to class? Should they?'. Journal of economic Persoectives, P16-74 </fnote>Looking at table 1 of appendix 6, we find that 3 out of the 6 coefficients on the variables are significant at the 0.01% level, if we test each of them with a t-test. Lectures attendance and A's at Alevel are not even significant at the 10% level. Hence, I then tried the model with different functional forms, before coming across my final model of exam performance below.  FORMULA  <heading>The estimated equation was as follows</heading> FORMULA  To justify the use of a quadratic term on lecture attendance, let us turn back to graph 3 of appendix 1. This shows that it is possible that a quadratic function could possibly fit the data better than a linear one, although that is open to criticism as the data is so varied. The argument on the logarithm on A's at A-level is similar, as a log function would fit this data better as graph 6 shows in appendix 1. This model uses the same variables as above, so the justification is the same but I have also included whether the student studies industrial economics in the equation because this had an unexpectedly large negative impact on exam mark and hence has a negative coefficient. Notice the negative coefficient on lecture attendance. This is contradictory to the theory above, but as it is in a quadratic, the interpretation is based on the differential of this term AND the squared term, which while negative will not have a huge impact upon exam mark. I think it is correct, seeing as lectures are more supplementary to lecture notes than anything else, particularly in statistics and therefore have less influence upon exam mark while still needing to be in the model because of the theory that they have an impact. Nevertheless it should really be positive, because for many students lectures are very important. The other variables all go along with the theory above. Testing the coefficients, we find that all 7 of the 8 coefficients are significant to the 1 percent level, with the other (that of how many of the student's parents attended university) being significant to 5% according to the p-values given in table 2 in appendix 6. This indicates that all of the variables have a significant impact upon exam mark. The F-test of the joint contribution of the variables also exceeds the critical value, so we can reject the null that none of the variables contribute anything to the model. This is to be expected since the R² is relatively large at 0.225 when you compare it to the regressions of questions 2, 3 and 4. The residual sum of squares is also lower than that of question 4, implying that there is less unexplained by this model. Although it appears I have a successful model, it is clear that there is a lot left unexplained by the model, seeing as R² varies between 0 and 1, and my result is at the lower end. Hence the model may be mis-specified. I may be including variables that are irrelevant; such as lecture attendance for instance, although this is unlikely, as this should make standard errors on coefficients bigger, and result in coefficients being insignificant in t-tests. However, I may have omitted some relevant variables, as this causes bias and this may have resulted in the lecture attendance variable being negative. Furthermore therefore I could have included other variables, such as sex, as prescribed by Siegfried and Strand, which had an insignificant effect on exam mark. However, having tried these variables, I found that they either were insignificant or made other variables insignificant. I also tried using the year intercept dummy; however, as hypothesis 4, appendix 6 shows, this only significantly improved the fit at the 10% level. Moreover I believe that the sample needs other variables not included in the survey such as stress and whether problem sets have been completed, which I believe would be a good approximate to 'motivation' which Romer emphasises as important in whether you do well, to be completely successful. <fnote>Unless the coefficient is 0 which is not true in this case or the co-variance between the included variables and omitted variables is 0 which again cannot be true as there are no 0 co-variances between variables. </fnote><fnote>Romer (1993), "Do students go to class? Should they?", Journal of Economic Perspectives, 171-2 </fnote>In conclusion, I have calculated a model of exam performance based on a number of variables, as given above. I think these have a significant impact upon exam performance, based on theory from economists such as Romer and also from my own experience. While nearly all the variables are significant individually at the 1% level and together at the 0.01% level, I do think there may be a better model as the  FORMULA  is quite low. However it difficult to offset increasing R² with not making your variables insignificant, as shown in question 4 where a number of variables are insignificant. 