<abstract></abstract><heading>1. Introduction</heading>γ -ray spectroscopy has been around since the 1960s and is used in a range of applications. In 1969 two satellites, called Vela 5A and Vela 5B, were launched into Earth orbit with γ-ray detectors intended to monitor atmospheric testing of nuclear weapons.[1] Substances that emit γ-rays can be injected into the body to provide radioactive tracing of such functions as blood flow, liver and kidney organs, and bone developments. In positron emission tomography an isotope is injected which emits positrons. Upon striking the normal matter inside the body two γ-rays are produced in opposite directions, which are detected, and used to pinpoint concentrations of blood.[2] γ-ray spectra are needed to help understand high-energy processes in our universe. The energy of a γ-ray can tell us how the ray was created. Predicting or explaining certain γ-ray activity can test theories we have about the universe. Thus γ-ray spectroscopy is a significant area of modern physics. Electromagnetic radiation with energy greater than 100 KeV is generally referred to as γ-rays. However, hard X-rays can also have this high energy. The difference is that γ-rays are photons emitted from nuclei and X-rays are emitted from de-excitation of atomically bound electrons. γ-rays interact in matter by three significant and distinct processes; photoelectric absorption, Compton scattering, and pair production. Pair production occurs in the intense electric field near the protons in the nuclei of the absorbing material.[3] The γ-ray disappears and an electron and positron are created. A γ-ray of energy greater than 1.02 MeV is required to create these particles. This type of interaction is seen as peak 2 m0c2 less than the main photopeak. Compton scattering occurs between the energies greater than several hundred KeV and less than around 5 MeV. The process involves the γ-ray photon scattering off an electron. The electron is given a forward knock and the photon can be scattered off in any direction. In two dimensions the interaction can be written as momentum conservation equations [4]:  FORMULA  (1)  FORMULA  (2) Where h is Planck's constant, is original frequency, ' is the new frequency, c is the speed of light in a vacuum, P e is the momentum of the electron. Solving the equations of momentum conservation in all three dimensions gives the new γ-ray energy as:  FORMULA (3)[5] Where m0c2 is the energy of the electron at rest, and the scattering angle. The extreme where = means a head-on collision and the photon loses the most energy. This is shown on spectra as the Compton edge. It is an edge since there cannot be any Compton scattering events detected between this energy and the photopeak. The energy of this Compton edge can be found by setting = in equation (3), so for a given initial energy h, the edge is at energy:  FORMULA  (4) Because the photons can be deflected through all angles from 0° to 180° they can have any energy from zero up to the Compton edge. This produces a continuum on the spectrum. The original equations (1) and (2) are based on the electron being free. The more likely scenario is that the electron is bound to an atom. In this case the Compton edge will not be so pronounced and will appear rounded off. The third type of γ-ray interaction occurs at energies up to several hundred KeV and is called photoelectric absorption. The γ-ray disappears as its energy is completely given to an electron. This photoelectron is freed from the atom and has the energy of the incident γ-ray minus the binding energy to free the electron. This binding energy is 33 KeV for the iodine K-shell and so for γ-rays of several hundred KeV the recoiling electron has most of the energy. As the electrons still bound to the atom rearrange, an X-ray is emitted to conserve energy. In iodine this characteristic X-ray is emitted 88% of the time.[6] Since the photoelectron carries the energy of the incident γ-ray it is possible to create a spectrum of γ-rays by detecting the photoelectrons and measuring their energy. The oldest method of creating a spectrum is to use a scintillator to convert the γ-ray into visible light and then a photomultiplier to convert the photon to an electron and amplify the current to a detectable level. This signal is converted from its analogue form into a digital signal that can be interpreted by a multi-channel analyser. This set up is depicted in Figure 1: <figure/>Scintillators can be organic or inorganic. Inorganic scintillators have impurities added called "activators". These activators add energy states in the band gap of the scintillator material that an excited electron can access when given energy from the γ-rays. The excited electron drops down to an activator ground state and releases a photon corresponding to the energy of the incident γ-ray . Refer to reference [7] for a more complete description outside the scope of this introduction. The scintillator photons are chosen in the visible range, and as a photon comes in contact with a photocathode the photon's energy is transferred to an electron. This electron then migrates to the surface of the thin photocathode before escaping the surface and going into the electron multiplier. The electron multiplier is a series of dynodes. The dynode material is chosen so that upon absorbing an electron, it reemits more than one electron. This secondary electron emission yield is sensitive on the incident electron energy, and temperature. Finally the electrons are absorbed on an anode and this produces a measurable current that will be proportional to the initial γ-ray energy. A complete photomultiplier tube is shown in Figure 2: <picture/>The output voltage is analogue, and is then digitised. Compared to the time taken for this digitalisation the scintillation, photoelectron emission, multiplication and detection happen quickly. Because the conversion takes longer than the measurement some measurements may be missed. The live-time is the time when the converter is observing the detector for peak voltages and not doing conversions. The difference between the actual time taken for the readings and the live-time as called the dead-time. The multichannel analyser does this conversion and stores the digital data. They can also perform such functions as adjust the gain, shaping time, pile-up rejection and spectrum stabilisation. These, and other facets of MCAs, are discussed in more detail in reference [8]. The end effect is that the MCA can display a spectrum of energies of the γ-rays and their respective count rates. A typical spectrum is shown in Figure 3: <figure/>The X-ray peak in Figure 3 is caused by the γ-rays striking material around the detector and through photoelectric absorption an X-ray is given off and detected. For example, γ-rays that strike the lead shielding of the detector produces 74.96 KeV lead X-rays. Backscatter peaks occur around 0.2 MeV and are caused by γ-rays that have been Compton scattered off materials surrounding the detector. Annihilation peaks are from pair production (discussed above) in the material surrounding the detector and thus occur at 0.511 MeV. The Compton edge, which theoretically should be a sharp edge, is rounded due to bound electrons having a spread of energies as well as the resolution of the detector. Multiple Compton events are caused by Compton scattering occurring outside the scintillator crystal, such as scattering off the table. The resolution of the detector is defined to be the full-width at half-maximum (FWHM) of the photopeak divided by the central energy of peak, the FWHM is shown in Figure 3. This is related to the relative detector efficiency by the peak-to-total ratio. The counts under the photopeak divided by the total counts detected gives the detector efficiency. The Compton continuum hence decreases detector efficiency. The probability that a nucleus in a sample will decay and emit a γ-ray is small and constant for a single nucleus. With many nuclei together the emission is independent, and if the half-life is much greater than the observation time, the emission will be constant too. Because the decay events are independent, random, and spontaneous the Poisson distribution can model the nuclear decay statistics. A binomial distribution would match too, as decay is a constant probability event during the short observation times relative to the half-life, but due to the large numbers of nuclei it is "computationally cumbersome." [9] Equation (5) gives the equation for the Poisson distribution:  FORMULA  (5) Which gives the predicted probability of measuring exactly x counts given that the mean is  FORMULA . The predicted variance is equal to this mean, and the predicted standard deviation is equal to the square root of this mean:  FORMULA  (6) This relation is a satisfactory test for the Poisson distribution. The aims of this experiment are to appreciate the statistical nature of the radioactive decay process and verify that radioactive is governed by Poisson statistics. During this the aim is to learn how to collect and interpret γ-ray spectra, to understand the practical difficulties involved in obtaining γ-ray spectra and in particular the effects introduced by the detector. Obtaining the γ-ray spectrum for a known source and explaining all the features contained in the data will objectify this. Identifying unknown γ-ray sources from their spectra will be performed along with an investigation of the energy dependence of γ-ray attenuation coefficients of lead, which will involve the measuring of the γ-ray attenuation of lead. <heading>2. Experimental Details: Calibration</heading>Calibration relates the channel numbers of the multichannel analyser with actual energies. Without calibration the real energies of the γ-rays would be unknown. However ratios such as detector efficiency would still be the same. The equipment used to detect γ-rays in this experiment is of the same kind as describes in Figure 1. The microprocessor is in a PC and scintillator is sodium-iodide crystal doped with thallium (NaI(Tl)). Sources of γ-rays were placed in the detector close to the scintillator crystal, as γ-rays are emitted in all directions the inverse-square law applies and so the closer the source and detector the more counts will be detected. These sources were 137Cs and 241Am, which have energies of 661 KeV and 59.5 KeV respectively. The software on PC was used to reset any spectrum currently displayed and then start recording data until the spectral peaks were clear, that is, until the signal-to-noise ratio was high enough to accurately place the energy photopeaks of the sources in a definite channel. The channel number the respective peaks were in were defined as having the energies stated above exactly. The MCA then uses a linear equation to define the energies of all the other channels. Because the way the calibration is carried out systematic errors are likely to occur. Firstly if the temperature of the apparatus changes after calibration the detected energies will appear different. Secondly the MCA might not be linear and so only making two exact measurements would just be a linear approximation. By calibrating the device it allows unknown photopeaks to be measured and thus can aid in the identification of unknown emission sources, which is part of the objectives of the experiment. Having the apparatus at a fixed temperature or having a temperature correction function would prevent the calibration drifting away from true as the local temperature varies. Having more sources of known photopeak energy would enable a non-linear calibration to be made, if the MCA is not linear. <heading>2.1.a MCA linearity: Details</heading>The part of the experiment will determine if the MCA is linear or not. After calibration a source of 226Ra was placed in the detector and after resetting the spectrum the MCA was allowed to take measurements. A live time of 180 seconds was sufficient to achieve a good signal-to-noise ratio for the photopeaks to be discerned. The decay energies, daughter nuclei and decay type were looked up in a data book and matched to the observed photopeaks recorded. The measured energy was then plotted against the expected energy to see if the MCA was linear. If it were, then a straight line would be the best fit. If not then the MCA would not be linear and the linear calibration would not hold true. <heading>2.1.b MCA linearity: Results</heading>The recorded data was saved in a file containing the counts per channel and the equation for the linear calibration. From this the graph on the output monitor can be reproduced. The γ-ray spectrum of 226Ra can be found in Figure 4. <table/>Refer to Figure 5 for a graph of the data in Table 1. From Figure 5 you can see the clear linear correlation between the measured energy and the expected energy for the same decay events. The errors are related to the resolution of the detector. This was defined as the FWHM divided by the energy of the centre of the peak. Thus the errors are shown below for each measured photopeak. <list> FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA </list>There is a systematic error involved whereby the measured value should be adjusted, this is done by multiplying by 0.85 and adding 91. <heading>2.1.c MCA linearity: Discussion</heading>The systematic error values, and the errors in measurement are irrelevant for this part of the experiment. It is only necessary to show that there is a clear linearity in the MCA. If the MCA were not linear then the line of best fit would be curved. Also the systematic error would be a function of higher powers. Linearity in the MCA means the calibration can be correctly assumed to be a linear function. As the calibration can be considered reliable the spectra of the unknown sources can be more positively identified than if there was uncertainty in the calibration or the linearity. Limitations of testing just one sample are that it is unknown if the linearity continues outside the range of the measured photopeaks. The error in measurement occurred from the detector resolution, as theoretically the detector should absorb all the energy and appear as a different delta-function for each peak. The systematic error is most likely due to calibration errors initially. Recommended improvements would be to test more than one sample, and test the calibration to remove the systematic error. <heading>2.2.a Poisson Statistics: Details</heading>This experiment will verify that the Poisson distribution is valid for radioactivity. After an initial calibration a 137Cs isotope was placed in the detector and data recorded for 60 seconds live-time. A region of interest was placed around the photopeak between energies 596.5 KeV and 738.9 KeV. The counts between these points were noted (the integral under the photopeak) and the spectrum reset. Then another 60 seconds of live-time recording made for the same region of interest. In total, sixty independent measurements were made. If the Poisson distribution given in equation (5) is valid, the conditions in equation (6) must be true, that is the variance must be approximately equal to the mean value. The variance can be calculated by the following equation:  FORMULA  (7) Whereby in this case, x represents the counts. <heading>2.2.b Poisson Statistics: Results</heading>The counts for the sixty measurements are given below in ascending order: <table/>The mean of these results is ~134,891. The square of the mean is 18,195,505,443. The mean of the squares is 18,195,657,033. The difference in these latter two values is 151,590. This is equal to the variance of the sample, given by equation (7). The standard deviation is the square root of variance, giving 389.3. Whereas the root of the mean is 367.3. This is a difference of 5.6%, which is a good enough correlation to state that the Poisson distribution is obeyed. If an outlier is a value further than three standard deviations of the mean, then the only outlier in the data is the lowest point, 133,633. Removing this datum leaves the root of the mean unchanged whilst lowering the standard deviation to 356.2. The difference between these corrected values is only 3%, a statistically insignificant difference, meaning the data is effectively Poisson. The error in the summation is given by the following equation:  FORMULA (8)[10] Where N is number of independent measurements. In this case the error is 47.4. <heading>2.2.c Poisson Statistics: Discussion</heading>As radioactivity obeys the Poisson distribution given in equation (5) the objective of verifying this has been achieved. Because the distribution is Poisson it shows that, statistically at least, over the timescales observed that the decay of nuclei is random. A disadvantage of this method of testing is that it takes time to get a significant number of independent measurements recorded. This is offset by the simplicity of verifying the distribution once the data has been collected and the photopeak integral automatically calculated. Because of the long timescale involved in taking all the measurements the temperature in the laboratory changed, and this caused the photopeak to wander off centre from the region of interest. If the photopeak went too far to either side then significant counts would be lost. This calibration issue was taken into account by setting the region of interest a good distance either side of the photopeak, without capturing any other peaks or Compton phenomena that could add systematic error to the results. This is an acceptable practice as it is only the count number that is important, and not the actual energy of the photopeak. Besides the systematic error by detecting photons not belonging to the photopeak, the other error is the statistical one shown in equation (8). This reveals that in order to improve the error by a factor of 2 it is required that 4 times the number of measurements are taken. This experiment could have been improved by taking twice as many measurements for half the time, as the statistical error would be less. Despite the randomness of radioactivity the measurements could not be "overlapped" to cut down experiment time, as this would lead to a correlation and the measurements would not be independent as required. <heading>2.3.a Spectrum and Detector Characteristics: Details</heading>Resetting the MCA and recalibrating, a γ-ray source in the form of 137Cs was placed in the detector. The MCA was allowed to measure data for 103.32 seconds live-time with a real-time of 109.30 seconds. This provided at least 10 4 counts under the photopeak, and consequently a good signal-to-noise ratio. Having such a precise spectrum is very helpful in spotting features in γ-ray specta, in particular the effects introduced by the detector. <heading>2.3.b Spectrum and Detector Characteristics: Results</heading>The spectrum can be seen in Figure 6. The spectrum was obtained from the MCA as it provided a list of channels and the counts in those channels. To get the correct energies also listed was the linear calibration equation. The key features are listed and can also be found on Figure 3, the typical spectrum. Note there is no annihilation peak in Figure 6, as the γ-rays do not have the energy to create the electron/positron pair. The X-ray peak around 73 KeV is most likely the 74.96 KeV X-ray caused but electronic excitation in lead. Relative detector efficiency, given by photopeak flux divided by total flux, was found to be:  FORMULA  Detector resolution, given by the FWHM divided by the central energy of the photopeak, was found to be:  FORMULA  The real-time minus the live-time divided by the total number of counts gives the dead-time, which was found to be:  FORMULA  seconds per count (±0.14%) at a count rate of 4663 counts per second. The energy of the Compton edge can be calculated using equation (4). Using h( as the energy of the photopeak (661 KeV) and the rest mass energy of an electron, the Compton edge is found to be at:  FORMULA  Similarly, equation (4) can also be used to find the location of the backscatter peak, which in this case is equal to around 184 (±5) KeV. <heading>2.3.c Spectrum and Detector Characteristics: Discussion</heading>Obtaining a good γ-ray spectrum was practically difficult in that it is hard to achieve the ideal theoretical model. The detector has a finite resolution, and the MCA has dead-time where measurements are being neglected. There are other materials around the detector that the γ-rays scatter off causing multiple Compton events, backscatter and X-ray peaks. Nonetheless a γ-ray spectrum was obtained and all the features contained in the data were explained. Some information about the detector was calculated, and it can be seen that the detector was not very efficient. Semiconductor diode detectors can improve the efficiency and resolution but have other drawbacks. The Compton edge is where it is theoretically predicted to be, but is rounded off and slightly spread out. This is a factor of bound electrons and finite resolution. The backscatter peak is located more around 200 KeV, slightly higher than calculated but still within theoretical bounds which state the backscatter peak always occurs at an energy of 250 KeV or less. The resolution of the detector is affected by a variety of contributions such as electronic noise, variations in scintillator response from impurities, and the photomultiplier tube gain from event to event. The temperature change of the photomultiplier tube can have a large affect on the resolution also. Because the spectrum was taken immediately after a calibration the temperature change was not great enough to affect the results significantly. It would be good to have higher energy γ-ray sources so the detection of annihilation peaks would be possible. If safely possible an investigation of the Cherenkov effect [11] or Bremsstrahlung radiation [12] might be useful in completing the objectives of this experiment. <heading>2.4.a Emission Spectroscopy: Details</heading>The apparatus was calibrated with the known sources as before. An unknown source was placed in the detector and its spectrum recorded and saved. Calibration was again performed and experiment repeated with another unknown source. The data was collected until there was sufficiently high signal-to-noise for the conclusions drawn to be firm. The features on the spectra were labelled. The photopeaks were matched up with the expected energies of sources given in a data table and through a process of elimination the unknown sources were identified. <heading>2.4.b Emission Spectroscopy: Results</heading>Figures 7 and 8 show the spectra for the two unknowns. Unknown A was determined to be sodium-22, which has a half-life of 2.60 years and photopeaks at 0.511 MeV and 1.275 MeV. These correlate with the measured photopeaks at 523 (±17) KeV and 1264 (±27) KeV. The data book gave that 99.95% of the photons were emitted at these energies, which fits with Figure 7. Unknown B was determined to be cobalt-60, which has a half-life of 5.27 years and photopeaks at 1.173 MeV and 1.333 MeV. These correlate with the measured photopeaks at 1185 (±15) KeV and 1336 (±16) KeV. The data book gave that 99.9% of the photons were emitted at these energies, which fits with Figure 8. Both unknowns have typical spectra that have been labelled accordingly. However, there is a spurious peak at 536 (±30) KeV in Figure 8. There is reasonable accuracy in the deduction of sources as all the photopeaks match within the errors allowed, the photon emission fits with the graphs, and the half-lives are long enough that is it likely they would be used in a laboratory experiment. <heading>2.4.c Emission Spectroscopy: Discussion</heading>The spurious peak in Figure 8 could possibly due to pair production, although this method of interaction is usually noted for sources with photopeaks at higher energies, such at >6 MeV. The spurious peak is at too higher an energy to be a backscatter peak, and too far away from the photopeaks to be a Compton edge. It is most likely, therefore, that this peak is a small photopeak. It is suspected it was caused by the unknown A source still in the vicinity. Identifying unknown γ-ray sources from their spectra was a primary objective in this experiment and it was met successfully. The labelling of the spectra further added to the objectives undertaken in part 2.3 to collect γ-ray spectra and explain their features. Limitations of only being able to deduce the isotopes listed in the data book might cause a problem if this experiment was applied elsewhere. Also the unknown sources were effectively pure; it would be considerably harder if the unknowns contained a mixture of radioactive isotopes. γ-ray spectroscopy is very useful for identifying unknown sources by measuring their spectra. It is conceivable that the MCA is combined with a database of isotope data and the process of detection could be automated. Due to only testing the sources once straight after a calibration they are very accurate which aided the identification. Thus temperature changes provided no noticeable systematic error. The errors are from the detector and other sources nearby adding unwanted photopeaks. A method to stop this latter error creation would be to shield the detector completely, or take a "background" count with no source in the detector and subtract it from measured spectrum. <heading>2.5.a Absorption Spectroscopy: Details</heading>If between the source and the detector the γ-rays are allowed to pass through an absorber of variable thickness then the attenuation with be exponential. This linear attenuation coefficient is given as:  FORMULA (9)[13] Where I is the flux measured, I0 the flux without an absorber, μ the attenuation coefficient and t the thickness. However, this is for a collimated beam of γ-rays. The scenario will most likely be one with bad geometry, where the detector can respond to γ-rays that have been scattered by the absorber, as shown below in Figure 9: <picture/>This would cause the measured counts appear larger than if the beam was collimated, and is called "Buildup". The equipment was calibrated and a 137Cs isotope placed into the apparatus, but not near the detector. This kept the distance of the source and detector constant throughout the experiment, as the divergent beam of γ-rays would be affect by the inverse square law. The flux was counted between energies of 591.4 KeV and 730.6 KeV for sixty seconds live-time without an absorber. This method was applied several more times with various thicknesses of absorbers between the source and detector. The absorbers were all square bits lead, and the thickness was measured with a micrometer on all four sides and averaged. <heading>2.5.b Absorption Spectroscopy: Results</heading><table/>Table 3 shows that the μ/ρ, the mass attenuation coefficient, is calculated to be 0.014 m 2kg -1 for lead. The expected value for the 661 KeV photopeak is around 0.011 m 2kg -1. The errors in the counts are related to the Poisson errors. The percentage error in the counts should be combined in a quadrature sum to find the percentage error in  FORMULA . Dividing by the thickness to determine μ adds in another quadrature sum error. <heading>2.5.c Absorption Spectroscopy: Discussion</heading>The aim to measure the γ-ray attenuation of lead was successful, although the error was not calculated. The expected value is lower than the measured value for the energy of the photopeak in this case. This is expected, as the energy range of the photopeak is where the Compton scattering attenuation mechanism is most prevalent. Thus the bad geometry of the set up yielded more detected counts than would be possible with a collimated beam due to these extra scattering events. An advantage of this method is that it depends only on the ratio of initial flux and absorbed flux, so it will work with any source regardless of its actual activity. The bad geometry means that the value obtained for the mass attenuation coefficient is unreliable. Improvements could be made to place the source down a heavily shielded tube to give it a collimated beam. Since γ-rays are such high energies they interact with matter more strongly than visible light photons and as such lens cannot be used to "focus" the beam. The time over which the readings were taken could have allowed the calibration to drift due to thermal changes, but there were no systematic errors introduced by this, as the temperature was stable. 