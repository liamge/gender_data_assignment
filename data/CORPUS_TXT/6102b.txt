<abstract><heading>Abstract</heading>Evolutionary computation (EC) as a subfield of artificial intelligence means design and application of computational model of evolutional approach which is based on the Darwinian theory. It refers a term of some computational techniques dependant upon the evolution of biological life in the natural world. Involved with combinatorial optimization problems, many kinds of EC models have been developed by some metaheuristic optimization algorithms, such as evolutionary algorithm (EA) which is a subset of evolutionary computation, including evolutionary programming(EP), evolutionary strategies(ES), genetic algorithms(GA), genetic programming(GP) and learning classifier systems. EC model can improve the electronic devices more intelligent to program itself without human preprogramming what was happening and without human intervention. It is widely used in the science and engineering area, such as innovative design, optimization, machine learning and flexible and adaptive system. Genetic algorithms (GAs) which is one of the most important EC techniques have been applied to solve practical problems in the rapidly growing field. Through three experiments of two maths function and a Robot Racing software which are all implemented by GAs method to evolve the parameters, it discern GAs have the positive impacts on the efficiency of searching optimized solutions to some specified problem. </abstract><heading>Introduction</heading>With the rapidly development of computer science and electronic engineering subjects, more and more advanced instruments those have the close relationship with human are invented to cause a digital resolution. They are changing the world and the human life. More and more hi-tech products are appearing among a variety of areas, from design of integrated circuit (IC) even to the application of artificial intelligent (AI) technology which is playing an important role in the modern world. AI is no longer only a movie which can not only be watched in its ever expanding influence to each corner of the world. The science of creating machines which can solve problems and reason like humans is usually referred to as artificial intelligence. AI can depend on different external situation to make a final decision like a reasonable human. Around us, it is easy to find that AI gives final opinions to help people make judgement on many issues in every day life. The most interesting application in the current age, is embedding AI technology into robot. However, most robots currently could only be considered as machines in our life but not intelligent. As stated by Murphy: "While robots are mechanical, they don't have to be anthropomorphic or even animal-like." For example, robot which delivers hospital meals to patients looks like a cart, not a nurse [1]. So the robot associated with AI technology should have the ability to solve some problem without the preprogrammed by engineer. Moreover, the ability of learning can not be ignored on AI robot. It refers that robot can feel the influence of environment automatically and program itself to search the optimized solution so that it could cope with the unpredictable issue it met. Subsequently, each behaviour of AI robot causes it to contact the external world, and perceive the information of feedback about the change of the world through some instrument like sensor. The signals received are transmitted to the control centre which affect its former target and find a new way to meet it, immediately followed by generating a new cycle of actions. In the mean time, from high level of programming angle, to get machines programming themselves to figure out a most suitable way to process the digital signal received, the EC method by people like John Koza of Stanford University has been used to improve this process to create such "intelligent machine". This approach integrates the evolutional concept into computational problems to select out efficient way through searching among huge number of possibilities for solutions. In biology, the target of evolution is to produce the desired individual that is highly fit the variable environment. The individual is survived dependant upon its fitness in environment. The theory of "survival of fitness" is Darwin stuff that "through reproduction, inheritance and the occasional mutation within a population, individuals or groups of individuals with similar characteristics within that population would flourish when placed in a particular environment". It is stated by Richard Gardiner who is trying to embed the EC method into his mobile robot "Antaeus" to make it have the learning ability, a practical experiment at Cybernetics department of Reading University. So the simplified law of evolution is a continuous circle in which the individual is evolved by random variation such as mutation and crossover, and the fittest one which has the "qualification" to survive could be picked up through natural selection, subsequently, their genetic stuff will be kept and past to a new generation to continue process in the same circle. <picture/>For the robot control in the real world, the adaptive program is desired to be applied on control system so that it can make each robot make good performance in facing the variable environment. As stated above, some computational approaches inspired by biological evolution which is a theory supported by "survival of fittest" and "natural selection" can be used to realize the adaptive system on robot control. "The candidate solutions represent each possible behavior of the robot and based on the overall performance of the candidates, each could be assigned a fitness value. Genetic operators could then be applied to improve the performance of the population of behaviors. One cycle of testing all of the competimg behavior is defined as a generation, and is repeated until a good behavior is evolved. The good behavior is then applied to the real world."[2] The software of robot racing is a competition for programmers and an on-going challenge for practice of Artificial Intelligence and real-time adaptive optimal control. It consists of a simulation of the physics of cars racing on a track, a graphic display of the race, and a separate control program (robot 'driver') for each car [3]. This software can roughly simulate the robot control condition in the continuing changed environment. The evolutional approach which is used to modify the software is GA which was invented by John Holland in the 1960s and developed by Holland and his students and colleagues at the University of Michigan in 1960s and 1970s. GA is integrated into the present software to evolve the parameters of each car. The time of each lap can be taken as the feedback which is the interaction with the environment. It reflects the result of the influence of GA and is directly transmitted into programming level to join the evolution. In this GA function, the lap time is fitness that illustrates how well the speed determined by those evolved parameters. It continually changes as parameters evolve. About the more details on evolution process and test result, will be showed in the following section of this report. Different from other evolutionary computation approaches which are used to solve specific problems, GA is to "formally study the phenomenon of adaptation as it occurs in nature and to develop ways in which the mechanisms of natural adaptation might be imported into computer system" [4]. Virtually, GA is a kind of adaptive algorithm based on the evolutionary ideas of natural selection. The basic techniques of the GA are designed to simulate processes in natural systems of evolution which is inspired by the principles first laid down by Charles Darwin of survival of the fittest. GA following the principle of "survival of the fittest" processes individuals over consecutive generation for solving the optimized searching problem. Each generation is consist of a variety of character strings or real-valued parameters those stand for the chromosome that seen in our DNA. Each individual represents a point in a search space and a possible solution. The individuals in the population are then made to go through a process of evolution. More details of implementation and application of EC will be illustrated later. So far, some basic idea and theory of EC and GA which is the popular EC approach are displayed above. This report is organized to discover the impact and development as well as some specific applications of EC. In the next section, the background and of EC are briefly introduced. To investigate how EC works on some practical problems, GA is applied to maths function to search peaks as well as the game software named robot racing to figure out the best parameters. Then the results of those three tasks will be illustrated and discussed to analyze the influence of GA. <heading>Background </heading>Evolutionary computation (EC) as a subfield of artificial intelligence means design and application of computational model of evolutional approach which is based on the Darwinian theory. "EC uses computational models of evolutionary processes as key elements in the design and implementation of computer-based problem solving systems. There are a variety of evolutionary computational models that have been proposed and studied which we will refer to as evolutionary algorithms. They share a common conceptual base of simulating the evolution of individual structures via processes of selection and reproduction. These processes depend on the perceived performance (fitness) of the individual structures as defined by an environment. More precisely, evolutionary algorithms maintain a population of structures that evolve according to rules of selection and other operators, such as recombination and mutation. Each individual in the population receives a measure of its fitness in the environment. Selection focuses attention on high fitness individuals, thus exploiting the available fitness information. Recombination and mutation perturb those individuals, providing general heuristics for exploration. " [5] Because EA is inspired by biological evolution, as mentioned above, reproduction, mutation, recombination, natural selection and survival of the fittest, so the illustration of EA can be offered by biological terms, although sometimes they do not have direct connection. To capture the main idea and structure of EA, the working flow of EA is list in the following lines. From lecture note of week 1:  FORMULA  Through the pseudo code above, the procedure of EA is briefly described. In the first generation P(0), individual population whose size is defined as a constant value by each EA is randomly initialized through EA model. The evaluation function is engaged to do the measurement work on each population, so a fitness value which is used to indicate its worth in some environment is added up to the individual. "Selection is often performed in two steps, parent selection and survival. Parent selection decides who becomes parent and how many children the parents have." [5] Children are produced by crossover, which exchanges information between parents. In the maths experiment which will be displayed in the following sections of this report, the approach of exchange on crossover is getting average value of parents. To increase the diversity, mutation function is introduced into the EA to perturb individuals. At the last step of each single procedure, the children are evaluated to decide who survives in the population. Then they are evolved from generation to generation in the loop applications of evaluation, selection, recombination, and mutation as mentioned above. <quote>"It is generally believed that EA perform consistently well across all types of problems. This is evidenced by their success in fields as diverse as engineering, art, biology, economics, genetics, operations research, robotics, social sciences, physics, chemistry, and others." [4]</quote>EAs mainly comprise genetic algorithm, evolutionary programming, evolution strategy, genetic programming and learning classifier systems. As the specific examples, most of these instances of techniques share the same evolution theory, however, when they are applied to solve some particular problems, different manners are implemented at each evolutional step in a variety of evolutionary algorithms, which consist of the choices of representation for the individual structures, types of selection mechanism used, forms of genetic operators, and measures of performance [5]. This report concentrates on the GA implementation. In the next several sections of this report, optimized solutions to the specific practical problems are figured out by evolving the related parameters with GA. Nowadays, GA plays an important role in the EC area as the most popular type of EA. "Genetic algorithms are typically implemented as a computer simulation in which a population of abstract representations (called chromosomes) of candidate solutions (called individuals) to an optimization problem evolves toward better solutions." [5] The application of GA is to search the optimized solution of a problem in the form of bit-strings and some neural networks, LISP expressions and real-valued vectors representation. In the basic structure of EA, selection, crossover and mutation, as three elemental types of operators, are involved to construct simplest form of GA. Basically, a simply GA is represented through the following step that is introduced in [4]: Start from a population of randomly generated individuals of chromosomes which are candidate solutions to a problem. Calculate the fitness of each chromosome in the population. Set a loop to repeat evolution stuff to produce the offspring. The fitness is evaluated in each generation, and based on fitness the individuals who have higher relative fitness are more likely selected to be the parents of current generation to produce "kids". Using those found out parents, process the crossover which is used to exchange the information between the parents to form offspring. By recombining parts of good individuals, this process is likely to create even better individuals With some low mutation probability, the offspring which is just produced are mutated through specific approaches to replace chromosomes in new generation. Its purpose is to maintain diversity within the population and inhibit premature convergence. Update the current population with the new generation. Repeat from step 2 which becomes current to start the next iteration of the algorithm. GA offers significant benefits over more typical search of optimization techniques, variation on the main structure of GA have been widely applied in diverse scientific and engineering topics such as optimization, automatic programming, machine learning, economics, immune systems, ecology, population genetics, social systems and so on. Because of the success of GA in these areas, more and more interests in GA have been sharply raised in the recent years by the researcher from any area. With the same theory of Darwinian concept which is survival of the fittest applied on GA, GP comes from the original work on genetic algorithm. "GP is an automated methodology inspired by biological evolution to find computer programs that best perform a user-defined task. It is therefore a particular machine learning technique that uses an evolutionary algorithm to optimize a population of computer programs according to a fitness landscape determined by a program's ability to perform a given computational task." [6] Although much of the theory associated with genetic operators is relied in GP as well, the hierarchical expression, which is manipulated in GP, is far different from the coded strings of GA. The hierarchical structure is a tree manipulation routine but not a flat and one dimensional string. Similar as GP, based on the fixed structure of program which is the only fixed thing, EP is evolved by its numerical parameters. Traditionally, Representation and operators were specialized for the application area which is evolving finite state automata for machine learning tasks. Nowadays, it is often used as optimizer with any representation, such as real valued vectors are using in population to solve the real valued optimization problems. Also for the traveling salesman problems, ordered lists are called and graphs orient to applications with finite state machines. From the lecture note of week 6, the basic EP was formed by three basic steps (1) Choose an initial population of trial solutions at random. (2) Mutate each offspring. (3) Select a number of solutions based on fitness. <figure/>Compared with EP, typically, ES is applied to real-valued parameter optimization. The main characteristic feature of ES concentrates on self-adaptive mutation using standard deviation of Gaussian distribution to make each individual have an adaptive mutation. Typically ES is applied to real-valued parameter optimization problems Nevertheless, during the recent years, interaction and communication among various evolutionary computation methods have been widely developed. "the boundaries between GAs, evolutionary strategies", evolutionary programming, and other evolutionary approaches have broken down to some extent." [4] Next section, GA method will be detailed and analyzed involved with actual examples. <heading>Methods, Results and Discussion</heading>The applications of GA have been spread to a variety of fields, because GA can effectively find an optimized solution in a complicated search space through input limited information so that it is an effective searching procedure compared with other method. Basically, when GA is applied to face the present problem, the performance of GA will depend on the elements: encoding candidate solutions and the method of evaluating the corresponding performance of candidate solution, which is used to test whether it is the optimized solutions. In this section, the applications of GA on a maths function and a software of Robot Auto Racing Simulation will be illustrated to explain and present how to implement GA on practical problem and how well to use GA to search the optimized solutions. <heading>Task 1 </heading>The task 1 is to figure out the maximum value of present maths function when the location of variable is between "zero" to "two*PI". A GA can be used to search the single peak of this function. It begins with a set of randomly selected points which is the input "x" variable of this function. Then the best performers will be selected out from those highlighted points through fitness testing. Crossover combines the best attributes from the most successful individuals of the population, and mutation randomly add up new characteristics that would produce better solutions. <figure/> FORMULA The function is "y=x +8 * sin (4 * x) + 6 * cos (5 * x)", and it has a single global maximum value. In MATLAB scientific maths package, the function is then plotted out to get an overview to test the result produced by GA. The figure 2 is the graph of that function. Through the implementation of GA used in this task, the method which is without having to solve the equation follows the pseudo code.  FORMULA  The algorithm begins with creating a structure of configuration and displaying the parameters which are similar as the chromosomes in the biology to indicate the genes. Fitness which can reflect the quality of the solution is declared in this structure. Then fitness, crossover and mutation which are three basic operators are defined respectively. The fitness function links the selection part to indicate weather the current members have the qualification to be selected out to reproduce next generation. So, specifically, the output value of "y" is set to be the fitness directly, because it can show the performance of corresponding input "x" in such peak searching problem. In the crossover function, using the part of the two randomly selected individuals to do the exchange between each other. After such exchange, the genes from parents are combined to be inherited to reproduce next generation. At the beginning, the method of crossover is to exchange the integral parts between a pair of parents, such as  FORMULA  So two children are produced for next generation and figure 3 illustrate how it works. Alternatively, what can be done is to get the average value of a pair of parents, so only one child is for next generation, such as  FORMULA  <figure/>The function of mutation is to make the solutions more diverse so that it can avoid the convergence which could happen among the solutions to focus some points. Then a bit larger search space will be exploited by the evolution process to produce better solutions of the problem. However, only part of members can be randomly selected out to do mutation, the percentage of the mutation should be set reasonably, otherwise, if too many members have the chance to be mutated, it will waste too much time on getting optimal solution and cause too much diversity. But optimal points will be lost, if only few individuals are mutated. Figure 4 displays the main structure of mutation function.  FORMULA  It can be seen from above that the mutation rate which is a percentage defining the chance of mutation is chosen at 5 per cent. "rand()" returns a integer between 0 and "RAND_MAX" which is an integer constant. So doing "(float)rand()/(float)RAND_MAX" will result in a random floating point number between 0 and 1. That expression will become true when that is less than 0.05 which means it has a 5% chance of succeeding. At this percentage, random numbers which are between - pi/2 and pi/2 are added up to the selected individuals to achieve the diversity. Then 2* pi is used to make the modified members locate at the area between 0 to "2*pi". After three GA operator functions, in the main function, population is initialized so that it contains random values distributed between specified minimum and maximum values. The size of population for each generation can influence the efficiency of GA. If there is a large population size of population, then many calculations of fitness are present to process which consume long waiting time of entire algorithm. To avoid the condition that GA converges a local optimal peak so quickly that misses global peak, the size of population can not be set too small. So, to search one global peak in the specified area, the size of population is set to 10. Subsequently, a loop which is counted by generation number is applied to evolve the x value where the global peak locates. The fitness function is called first to calculate fitness for the population in the current generation. For the selection part, the population should be put into a kind of order. In this problem, because the target is to search the peak of function in the specified area, moreover, the fitness is represented by y value, so the order should be ascendant. The x value is sorted at the ascendant order depend on the fitness. The method used is "bubble sort".  FORMULA  Following the sorted order, first top 5 members are randomly picked out to do crossover and mutation so that the fitter member will have a greater chance of reproducing. Therefore, in successive generations, the fitness of each member on average will be continuously higher.  FORMULA  "r1" and "r2" are the random integer numbers from 0 to 4. It means any two members list at the top 5 in the current generation have the same probability to be picked out to do crossover and mutation. Moreover, in the crossover function, if a pair of parents produces one child, the crossover and mutation must be processed ten times. Otherwise, if there are two children per time, then the counter "i" of this loop should be set to 5. So a new generation is produced to replace the current one. After 1,000 generation, the peak can be figured out. The output of the software is:  FORMULA  Nevertheless, among several tens of experiment, there is a strange unreasonable result.  FORMULA  The reasons why this condition could happen seem like that the optimal values have not been traversed by search function to reproduce or searched optimal point is lost due to random crossover and mutation. When producing offspring, there is high probability of crossover and mutation happening on the individuals even including the optimal point. So a number of good individuals are destroyed by crossover and mutation. To avoid loss of the best found individuals caused by the above reasons, elitism can be introduced into the GA, and put it at the position ahead selection. Elitism is to force GA to copy some better individuals directly to offspring, so those best chromosomes can be kept at each generation. And all the rest members can be constructed through the normal way, such as crossover and mutation. "Elitism is important since it allows the solutions to get better over time. If you pick only the few best parents, and replace always the worst, the population will converge quicker... this means all the individuals will more or less all be the same."[7] Because of the contribution of elitism, the performance of GA can be sharply improved. In task 1, to figure out the maximum value in the specified area, only the first chromosome need be copied to the next generation after bubble up sorting, which is the fittest individual. And process crossover and mutation to construct other members for new generation. <heading>Screenshot of task 1 output: </heading><picture/><heading>Task 2</heading>The requirement of task 2 is to find the values for the four highest peaks of function: y=x+8*sin(4*x)+6*cos(5*x) between x and two*pi. Based on the concept and application of GA in the task one which is to search the maximum value, some details in the algorithm should be modified. What is intended to do for searching first four peaks in the present function, is to figure out all the x values which locate at the peak positions. What is meant by this is that all the selected x values can generate the peaks so that the question is transferred into searching first four highest output values among the selected x input which can produce the local peak values. Subsequently, they are processed by GA as task 1.  FORMULA  Above algorithm is applied when doing random x value to make the selected x which is for local peak so that they can be used to generate first four global peaks. Also it is utilized in the main body when mutation function is called at each generation. The first four values in the sorted array should be the ideal output. However, it does not work. The reason considered is that the searching area that is between 0 and 2*pi is too narrow so that the possibility of finding suitable points through random approach is too low. When extend the searching area from 2*pi to 20000*pi, still there is no output. So the approach applied in task 2 is not successful. <heading>Task 3</heading>Task 3 is to embed GA into robot racing. The software of robot racing is a competition for programmers and an on-going challenge for practice of Artificial Intelligence and real-time adaptive optimal control. It consists of a simulation of the physics of cars racing on a track, a graphic display of the race, and a separate control program (robot 'driver') for each car [3]. GA is applied to search the best values of some specific parameters which are defined already for cars. So GA can figure out the optimized values of those parameters which will influence the speed of car to realize the best performance for each one. In one of the present car files, BURNS, all the related parameters are list. CORN_SPD_CON which determines how fast to take corners is selected to be evolved by GA. Compared with the basic application of GA in task 1, the input is corner speed and output is lap time which can be returned from main function when processing the racing programming, moreover the lap time returned can reflect the influence of GA on racing corner speed. So following the approach in task 1, set lap-time which is output as fitness. If the lap time is shorter, then the corner speed will be fitter. So depend on the fitness that is set to each value, all the values in the current generation should be sorted at the ascend order opposite to the order in task 1which is at descend order. All the rest GA processes are same as what have been done in task 1, such as selection, crossover and mutation. When finishing last generation, the first individual which is the evolved value making the lap time be shortest is optimized final corner speed.  FORMULA  <picture/>The lap time is getting shorter with the growing of generation, and finally the optimized corner speed can be found. Furthermore, not only corner speed can impact the lap time, but also all the rest of parameters have vital contributions on the racing speed. So, all the parameters can be evolved by GA to get a group of optimal parameters to improve the performance of car to be perfect. <heading>Conclusion </heading>From the statement of theory and three applications on practical problems in this report, it is obvious to discern that EC is a powerful tool to solve problem in a wide variety of scientific and engineering research area. It has been developed to a field which is importing biological technology into computation design. As the most popular evolutionary algorithm, the application of GA causes a great leap in development of intelligent computation. Through the exam on the maths function, it can be seen that GA can solve the problem of searching maximum value and first four highest peak values, moreover, compared with the figure plotted out by MATLAB, the results are precise but only a bit error around 0.01 on x value. Meanwhile, GA also has good performance in real world problem which is a simulation of car racing. Rely on the output file including time of each lap, which shows the time is getting shorter and shorter, it can be figured out that the parameter is evolved to be fitter and fitter with this search approach inspired by biology theory. However, only one parameter of car is evolved in this report, if a set of parameters of one car can be processed by GA as well, the performance of the car will be completely perfect after several laps. However, in the area of working electronic devices, still some problem can not be solved due to scalability. To cope with more complex conditions, the traditional approach of EC must be added up information by human, because all the parameters in the conventional GA method need to be defined to corresponding binary value. It refers that the EC approach as mentioned in this report is lack of one important nature like element, development. As stated by Peter Bentley, who is the head of the Digital Biology Group at University College London, "The idea is that, by incorporating development, you avoid the one to one correspondence between a gene and a parameter. We are trying to get to the point where the genome is more like a recipe; a set of instruction should grow, rather than a complete blueprint specifying every last detail in advance."[8] So, in this open area, much work such as how to implement it into algorithm and how to incorporate with other field knowledge should be considered to improve EC to realize the dream of completely natural computation method in AI world. 