<abstract><heading>Abstract (overview/synopsis of work and results/conclusion)</heading>A study into the various approaches available in Intelligent Systems Engineering has been carried out. The context for this piece of work, as well as describing the theoretical aspects and simulation results, has been that of the XNOR problem. It was found that Expert Systems, Genetic Algorithms and Fuzzy Logic would be acceptable approaches to this problem. The report highlights key points and includes an appendix with some new programs that were created. </abstract><heading>Introduction</heading>This report aims to describe the principles and relative merits of some Intelligent Systems Engineering approaches. The approaches to be discussed are Expert Systems, Unsupervised Learning, Supervised Learning, Genetic Algorithms, Fuzzy Logic and Neuro-Fuzzy. Besides looking at some of the theoretical aspects and most of the simulation results for these approaches an attempt will also be made. Context: solution to XNOR problem. This has been chosen since it is a simple problem that given the 15 pages suggested page limit of this report will not require multiple graphs. For fuzzy problems the idea is taken further by having multiple input gates and the input values been in the range -2 to +2 instead of fixed at -1 to represent logic low and +1 to represent logic high. Here is the XNOR gate: <figure/><table/>This can be represented in a matrix as:  FORMULA  <heading>a) Expert Systems:</heading>Expert systems attempt to make knowledge based decisions often using if...then type rules. They should only be used for applications that cannot be easily or cheaply solved by existing software or human intelligence. They work from large knowledge bases that contain data selected to help the expert system perform its function. In essence, a rule-based expert system, uses a combination of it's 'if...then' rules to make decisions. Other ways to implement expert systems are Frame-based, Procedure-oriented, Object-oriented, Logic-based and Access-oriented. An example of the rule-based type is found in the file in 'exsys.m', here are its contents: <quote>%EXSYS A simple example of how an expert system works debt=500;request=30000; income=14000;rating='good';job=6; TCF=1; % Rules (Confidence factors are multiplied) if debt+request>5*income,decision='deny',end if debt+request<=5*income,amount='okay',end if strcmp(rating,'excellent') & strcmp(amount,'okay'), ... decision='approve',TCF=.95*TCF;end if strcmp(rating,'poor') & strcmp(amount,'okay'),decision='deny',end if strcmp(rating,'good') & strcmp(amount,'okay'),risk='okay',TCF=.9*TCF;end if job>=5 & strcmp(risk,'okay'),decision='approve',TCF=.85*TCF;end if job<5 & strcmp(risk,'okay'),decision='cosign',TCF=.75*TCF;end fprintf('Confidence factor: %5.3f\n',TCF); </quote><figure/>The 'strcmp' function [strcmp(string1, string2)] returns 1 if string1 and string2 are the same, returns 0 otherwise. As can be seen this is using the confidence factor (TCF) to provide a representation of how sure of the use of the piece of knowledge used at each step will result in the correct output. As more rules are used the confidence therefore decreases. The output is shown below: <quote>>> exsys amount = okay risk = okay decision = approve Confidence factor: 0.765 >> </quote>This could of course be decided by human intelligence, however, the main goal of expert systems is to provide human-like answers but much more quickly. This approach to intelligent systems cannot or should not be used for mathematical or logical problems such as the XOR problem. It can be used for types of problems that some of the other approaches cannot, such as assisting supervisors and managers with situation assessment and long-term planning. The problem with expert systems is that they take an increasingly exponential number of man-years to develop depending on the complexity of the knowledge-base. This is due to the methods available for knowledge input and the way knowledge is extracted from data and interpreted. This particular example program also has another flaw in that it can give contradictory results given particular input data. This is because some outputs can be given more than once if certain conditions arise. To improve this particular expert system it would therefore be necessary to modify the rules to make sure that it can under no circumstances contradict itself. <heading>Can an expert systems be used to solve the XNOR problem? </heading>To do this a new MATLAB program is created: <quote>%XNOR EXSYS - Test to see if an expert system can be used for the XNOR problem input1 = 1 input2 = 0 if input1==input2 fprintf('input1 XNOR input2 = 1'); else fprintf('input1 XNOR input2 = 0'); end </quote><figure/>The output is: <quote>>>  input1 = 1 input2 = 0 input1 XNOR input2 = 0 >></quote>Of course the input variables 'input1' and 'input2' can be changed to test other outputs. However, it is pretty obvious that it will work but that the use of expert systems for the XNOR problem is a bit overkill as it is just a maths problem. <heading>b) Unsupervised learning</heading>This approach is concerned with the use of neurons to learn to generate a correct output from an input. The neuron is first trained on lots of data which modifies its weights and then tested on similar data to produce the correct result, that is for the input data to be clustered or grouped together. The program 'uhlr.m' demonstrates this: <figure/><quote>>> uhlr Vector 1: y = sgn( 0.50) = 1 new weight vector : W=[ 2.00 1.50 -0.50 0.00] Vector 2: y = sgn( 0.50) = 1 new weight vector : W=[ 1.50 2.50 -0.50 1.50] Vector 3: y = sgn( -1.75) = -1 new weight vector : W=[ 2.50 2.50 0.50 2.00] >></quote>For an n×m matrix of input data,  FORMULA  so there is 3 input vectors x,  FORMULA ,  FORMULA ,  FORMULA . The transfer function for the neuron looks like this: <figure/>Thresholding is at zero, so the input has to exceed 0 for the neuron to fire. This is implemented in the program through the use of 'sgn' or 'hardlims' within the 'hebbu( )' function. Define  FORMULA  [Equation 1] The change in weights is:  FORMULA  [Equation 2] Weights increase if yx is positive Weights decrease otherwise Assumptions: Learning rate, η, is 1 No prior knowledge about the grouping (no target is defined), the neuron needs to learn it so we can test it. The maths showing the production of the outputs for the three vectors has been shown in Assignment 2 and will therefore not be repeated here. Also see Lecture 5 notes for details on the step-by-step maths. For x1:  FORMULA  For x2:  FORMULA  For x3:  FORMULA  <table/>So the results show that the unsupervised learning has found that x1 and x2 belong to one class (they both have an output of 1) and x3 (has an output of -1) to another. To see if the result is justified would require a plot of the input data to be made and the clustering of the data vectors assessed by inspection. Since it is not possible to visualize 4-D data, I have created the program 'uhlr4Dto2D.m' (a copy of this can be found in the appendix). This plots the 4-D data in two 2-D graphs shown in Figure 7. The black dashed lines indicate possible separation lines and show that indeed it is possible to classify x1 and x2 into one class and x3 in a separate second class. <figure/><heading>Can unsupervised learning be used to solve the XNOR problem? </heading>To see how it holds up to the XNOR problem the following new program, 'xnoruhlr.m', was created. Note also that now the weights do not start with defined values but are given random values so that the neural network can modify them and in theory truly 'learn'. <quote>% UHLR trains a neuron with the Unsupervised Hebbian learning rule % Test for XNOR functionality % Define the input dataset P=[ -1 1 -1 1 -1 -1 1 1]; % Initialises the weight vector w [w b]=rands(1,2); % Now execute the Hebbian Learning Rule nepcs=1; % Number of epochs : 1 lr=1; % Learning rate : 1 hebbu(w,P,lr,nepcs) </quote><figure/>When repeatedly executed the output from this produced every possible combination of classification of the outputs possible, therefore, it was unable to classify the outputs for an XNOR function by itself. Therefore unsupervised learning by the Hebbian learning rule is entirely unsuitable in the context of the XNOR problem. Of course, use of a bias made no difference to this problem as was seen in Assignment 2 in 'uhlror.m' where it tries to use the unsupervised Hebbian learning rule on the OR-function. In fact after changing the 'uhlr.m' file to my 'xnoruhlr.m' as shown above (see also Figure 8) it comes out identical to 'uhlror.m' because for unsupervised learning, data vectors each of only length 2 could represent the input to any 2-input logic gate so of course it cannot produce the desired output. Another type of unsupervised learning is to use the Kohonen learning rule. This works by identifying common features in the arrangement of the data. The XNOR problem was simulated in 'xnorklr.m' (see appendix) but when applied to the XNOR problem proved fruitless purely because the input data for the XNOR problem is linearly separable. <heading>c) Supervised learning via shlr.m, plr.m, alr.m, dlr.m and mlp.m</heading>Supervised learning uses target vectors to define what the output should be for the given inputs so that the neural network can learn and modify its weight values so that the input is always mapped to the correct output. Target = t or a vector, ti Output = y = t, or in vectors, yi = ti The change in weight  FORMULA  Therefore new weight  FORMULA  <figure/>As for the unsupervised learning, the thresholding is at zero so the input has to exceed 0 for the neuron to fire, hence using combinations of positive and negative inputs allows the neurons to fire or not fire and so create the learning network. This is implemented in the program through the use of sgn or hardlims within the hebbu( ) function. The program 'shlr.m' uses the same input data as for, that is values for x1, x2, x3, η ( = 1) and w. But now there is the vector t;  FORMULA  For x1:  FORMULA  For x1:  FORMULA  For x2:  FORMULA  For x1:  FORMULA  For x2:  FORMULA  When the program is simulated these theoretical calculations are shown to be correct: <quote>Vector 1: target : 1 ; output: y = sgn( 0.50) = 1 Vector 2: target : 1 ; output: y = sgn( -0.50) = -1 wrong output, new weight vector : W=[ 0.50 1.00 -1.00 1.50] Vector 3: target : -1 ; output: y = sgn( -0.25) = -1 Vector 1: target : 1 ; output: y = sgn( 1.50) = 1 Vector 2: target : 1 ; output: y = sgn( 3.00) = 1 Learning successful! >></quote>So it only required 1 weight change (w1 →w2) as opposed to the unsupervised Hebbian learning rule which changed the weight 3 times. The supervised Hebbian learning rule can be used when there are targets, but the unsupervised Hebbian learning rule may also be used to locate other patterns in the data that would not be found with a supervised learning since it is trying to match its outputs to the target. <heading>Can the supervised Hebbian learning rule (SHLR) do the XNOR problem? </heading>New program 'xnorshlr.m' attempts to answer this question. <quote>% SHLR trains a neuron with the Supervised Hebbian learning rule %Test for XNOR functionality % Define the input dataset P=[ -1 1 -1 1 -1 -1 1 1]; % Define the targets T=[1 -1 -1 1]; % Initialises the weight vector w [w b]=rands(1,2); % Now execute the Hebbian Learning Rule maxepcs=5; % Number of epochs : 5 lr=1; % Learning rate : 1 hebbs(w,P,T,lr,maxepcs) %Bias not used</quote><figure/>Figure 10 shows that the program simply cannot learn because the relationship between inputs and outputs is not linearly separable. On the above plot this can be seen since it is impossible to place a separation line between the two classes ( + ) and ( ° ). Again, as for 'xnoruhlr.m' the use of a bias made no difference. <heading>d) Genetic algorithms via optsq.m and gaxor.m</heading>Genetic algorithms can be used to solve problems that would otherwise require an exhaustive approach to solution finding. This can have substantial benefits in terms of savings in both time and cost. In 'optsq.m' the function to be optimised using a simple genetic algorithm is defined as x2. The four stages are: Reproduction, Mating, Crossover and Mutation. The population is a random 5 bit binary number. These represent a population of chromosomes that are to be improved, that is maximised, so ideally they will all be set to the highest value as a result of the genetic algorithm. <quote>Cost function encoding as binary successful Fitness statistics Generation Maximum Minimum Mean Std. dev. 0 676 0 299.25 301.891 1 784 16 463.25 361.905 2 784 324 655.25 222.35 3 784 729 742.75 27.5 4 841 676 743.75 69.4808 Genetic algorithm converged. Initial population: 0 0 0 0 0 (0) 1 0 1 0 0 (20) 0 1 0 1 1 (11) 1 1 0 1 0 (26) Generation 1 Reproduction: 1 0 1 0 0 (20) 0 1 0 1 1 (11) 1 1 0 1 0 (26) 1 0 1 0 0 (20) Mating: 1 0 1 0 0 (20) 1 1 0 1 0 (26) 0 1 0 1 1 (11) 1 0 1 0 0 (20) Cross-over: 1 0 | 0 1 0 (18) 1 1 | 1 0 0 (28) 0 | 0 1 0 0 (4) 1 | 1 0 1 1 (27) Generation 2 Reproduction: 1 1 1 0 0 (28) 1 1 1 0 0 (28) 1 0 0 1 0 (18) 1 1 0 1 1 (27) Mating: 1 1 1 0 0 (28) 1 1 0 1 1 (27) 1 0 0 1 0 (18) 1 1 1 0 0 (28) Cross-over: 1 1 | 0 1 1 (27) 1 1 | 1 0 0 (28) 1 0 0 1 | 0 (18) 1 1 1 0 | 0 (28) Generation 3 Reproduction: 1 1 0 1 1 (27) 1 1 1 0 0 (28) 1 1 0 1 1 (27) 1 1 0 1 1 (27) Mating: 1 1 0 1 1 (27) 1 1 0 1 1 (27) 1 1 1 0 0 (28) 1 1 0 1 1 (27) Cross-over: 1 1 0 1 | 1 (27) 1 1 0 1 | 1 (27) 1 | 1 0 1 1 (27) 1 | 1 1 0 0 (28) Generation 4 Reproduction: 1 1 1 0 0 (28) 1 1 0 1 1 (27) 1 1 0 1 1 (27) 1 1 0 1 1 (27) Mating: 1 1 0 1 1 (27) 1 1 0 1 1 (27) 1 1 1 0 0 (28) 1 1 0 1 1 (27) Cross-over: 1 1 0 1 | 1 (27) 1 1 0 1 | 1 (27) 1 1 1 0 | 1 (29) 1 1 0 1 | 0 (26)</quote>As the program runs it shows the result at each stage of reproduction, mating and crossover. Mutation is rare and shows up as a difference in the population before and after reproduction. The first population is 1, 20, 11 and 26. <heading>Reproduction:</heading>The fitness of each chromosome is evaluated using the x^2 function. A chromosomes ability to reproduce is proportional to its fitness. 20 has the highest fitness value since it reproduces twice, whereas 11 and 26 reproduce only once and 1 does not reproduce at all. Therefore, in reproduction selection principles are applied. <heading>Mating:</heading>Pairs of chromosomes are mated by randomly choosing two for crossover. These were chosen to be (20,26) and (11,20). <heading>Crossover:</heading>For each of the pairs the crossover site is determined randomly. In this example this means which bit will be exchanged. For 20 and 26 this was the 4 th most significant bit and so 8 was subtracted from 26 and 8 added to 20 resulting in 18 and 28. Similarly, for 11 and 20 except their most significant bits were swapped so 16 was subtracted from 20 giving 4 and 16 added to 11 resulting in 27. This process repeats with the new generation of 18, 28, 4 and 27. This time 28 reproduces twice and 27 and 18 reproduce once each. And so on and so on... In the end the output does not achieve the maximum possible output of 31 but achieves only 29. This is because the program is a bit limited with only 4 chromosomes and 5 bits of coding. Increasing these parameters in the program produced better results. 'gaxor.m' simulates the XOR problem. This aims to find an MLP architecture for solving the XOR problem. The arrangement of neurons is shown below and it is used to train up to 10 generations of 16 chromosomes. <figure/><table/>This is the constraint matrix showing what is linked to what and where a bias can be added. For example there is a 1 in the top left of the table so there is a link going from unit 1 to unit 3. Not all possible connections are allowed as it is a forward-feeding network. The training parameters such as learning rate and number of 'epochs' are definable. The 'Fitnn' function trains the MLP using the gradient descent algorithm. It needs smallest sum-squared error to get outputs closest to targets. The fitness function is f(x) = 4*NE - E, where X = number associated with architecture, NE = number of examples and E = sum squared error. <quote>>>  Cost function encoding as binary successful.  Fitness statistics Generation Maximum Minimum Mean Std. dev.  0 15.9873 11.9847 12.4127 1.06036  1 15.9872 11.9362 12.5791 1.3802  2 15.9576 11.9787 12.4239 1.06675  3 15.987 11.9798 12.5913 1.10035  4 13.9735 11.9772 12.478 0.763031  5 15.9705 11.9729 12.9844 1.10497  6 15.9716 11.9457 12.8949 1.13119  7 15.9729 11.9673 12.7641 1.38685  Genetic algorithm converged.  Connectivity constraint matrix: from : 1 2 3 4 5 bias 3 1 1 0 0 0 1 4 1 1 0 0 0 1 5 0 1 1 1 0 0 Fitness: 15.9840 Output: -0.9473 0.9299 0.9473 -0.9255 >></quote>The fitness value is fairly high indicating that a solution to the XOR problem has been implemented to a very high degree. Indeed inspection of the output shows (to 2 d.p.) -0.95, 0.93, 0.95, -0.93. This is approximately -1, 1, 1, -1 which is the target vector. It is worth noting that upon repeat executions of the program different solutions are found that still work. That is, the connectivity matrix can be different and also the biases to produce the same result. To apply this to the XNOR problem would be trivial and obviously work as it does for XOR and so the discussion of this result will be raised in the Discussions & Conclusions section of this report to allow a more concise comparison with the other possible approaches. <heading>e) Fuzzy logic via bfso.m, finf.m and flc.m</heading>Basic Fuzzy Set Operators are demonstrated in 'bfso.m' uses the fuzzy subsets F1={A/0.5 B/0.7 C/0.3 D/0.1} and F2={A/0.1 B/0.9 C/0.5 D/0.7 E/0.9} to demonstrate some Basic Fuzzy Subset Operators. These are: <list>Intersection: min operator, covers possibility of both occurring, i.e. AND-functionUnion: max operator, covers possibility of either occurring, i.e. OR-functionComplement: f(x)=1-x, i.e. NOT-function</list>Note how possibility is different to probability. This is why the fuzzy subsets add up to greater than 1, if they were probabilities then they would have to add to 1. This is essentially how fuzzy logic works by allowing overlap of the fuzzy subsets. The product of fuzzy subsets are added and pairs of elements from F1 and F2 form new elements. The minimum of the memberships of the two elements is the new elements membership. For example (D, E)/0.1 comes from D/0.1 in F1 and E/0.9 in F2 because D has the lower possibility of 0.1 compared to E's possibility of 0.9. Fuzzy Associative Memories are demonstrated in 'finf.m' which defines normalised (across the row of numbers) vectors. To implement the AND and OR functions the min and max operators are used to build the Fuzzy Associative Memory (FAM). <table/><table/><quote>>>  Normalised vectors: 1.0000 0.2500 0 1.0000 0.6667 0 1.0000 0.6667 0 0.2500 1.0000 0 y1 AND y2: L M H L 0 0 0 M 0 0.2500 0.2500 H 0 0.6667 1.0000 y1 OR y2: L M H L 0 0.6667 1.0000 M 0.2500 0.6667 1.0000 H 1.0000 1.0000 1.0000 >></quote>It would not be possible to use this type of fuzzy logic for the XNOR problem since it only uses the min and max operators which are of no help. 'Flc.m' demonstrates Fuzzy Logic Control. This shows a good demonstration of how the fuzzy subsets can be shown graphically as in Figure 15. The output is an automatic grouping of the input data, the 4-D data seen throughout much of the examples. The membership functions are chosen by the program in such a way that given the input data it will be able to use a combination of the fuzzy subsets and if-then statements to produce classification outputs. <quote>>>  FLC Fuzzy Logic Control example seen in class Original dataset: 1.0000 -0.5000 -1.0000 //y1 (dashed line, dotted line, dash-dot line) 1.5000 1.0000 0 //y2 (dashed line, dotted line, dash-dot line) 0.5000 0 -1.0000 0 1.5000 -0.5000 Outputs: 1 1 -1 Rules used: 1. If (y1 is High) and (y2 is High) then (output is High) (1) 2. If (y1 is Low) and (y2 is Low) then (output is Low) (1)  3. If (y1 is Low) and (y2 is High) then (output is High) (1) >></quote>So the system classifies the input vectors successfully when compared to for example Figure 7 which shows the likely clustering of this set of input data. This is forward chaining or Modus Ponens where the consequences are discovered from the causes (the output from the input), otherwise it will be backward chaining or Modus Tollens (search for causes to give outputs). <figure/>In Figure 15 the vertical lines in the plot of y1 represent the first co-ordinate of each of the three vectors. Looking at the first vector:  FORMULA  We can see the first two co-ordinates shown as the long dashed lines in the plots of y1 and y2 and that both of these belong to the fuzzy subsets 'High' (shown by their position within the membership functions. Hence, looking at the three rules used we can see that it is correct for the first output to be a 1 since only rule 1 has been activated. For the second vector:  FORMULA  The first two co-ordinates have been shown as the dotted (or short-dashed) line in the plots for y1 and y2. - 0.5 belongs to the 'Low' fuzzy subset of y1 and 1.0 belongs to the 'High' (and possibly 'Medium'???) fuzzy subset of y2. Therefore rule 3 has been activated and the output is correctly shown as high, or a 1. For the third vector:  FORMULA  First two co-ordinates shown as dot-dash lines in plots of y1 and y2. - 1.0 belongs to the 'Low' fuzzy subset of y1 and 0.0 belongs to the 'Low' fuzzy subset of y2 Unfortunately this type of Fuzzy Logic is also unsuitable for solving the XNOR problem since the rules used are to determine classification which just wont work for XNOR input data. <heading>f) Neuro-Fuzzy via nfa.m, nfo.m and nfn.m</heading>The Fuzzy Propagation Algorithm (FPA) uses fuzzified data as input to a neural network. The 3 applications to be studied in this section are Neuro-Fuzzy AND, NOT and OR. <figure/><figure/>'nfn.m' implements the Neuro-Fuzzy NOT function. It defines the signal to complement, x = 0.25, and defines the signal and weight vectors p = [x 1] and w = [-1 1] respectively. It then executes 'fpa.m' which implements the FPA for any signal and weight. It works by first sorting the inputs using the Matlab function 'sort'. The differences are computed by subtracting each value in the signal vector from the following one. The weights are summed cumulatively by adding them from 1 to n, starting with the last one. The weights are thresholded before the output is created. <quote>>>  Reordered signals and weights: Signals : 0.25 1.00  Weights : -1.00 1.00  Difference between neighbouring pairs: 0.25 0.75  Combined weights: 0.00 1.00  Thresholded weights: 0 1  Output: 0.75 >> </quote><figure/>The signals were already in ascending order, [ 0.25 1 ], so they were not re-ordered. The difference calculation only affects the second value, 1.0 - 0.25 = 0.75 = complement of input. The new weights are found (-1 + 1 = 0 and 1 stays as it is) and thresholding does nothing here since they are already 0 and 1. Output = weighted sum of differences = (0*0.25) + (1*0.75) = 0.75 = the complement of the input. Hence it is performing the NOT function correctly. Neuro-Fuzzy OR is implemented in 'nfo.m' which is similar to 'nfn.m' except the signal to be 'OR-ed' is of course different, p = [1 .25 0], and the weight vectors are simply a row of 1's. <figure/><quote>>>  Reordered signals and weights: Signals : 0.00 0.25 1.00  Weights : 1.00 1.00 1.00  Difference between neighbouring pairs: 0.00 0.25 0.75  Combined weights: 3.00 2.00 1.00  Thresholded weights: 1 1 1  Output: 1.00 >></quote>This time the inputs are re-ordered from [ 1 0.25 0 ] to [ 0 0.25 1 ]. Again, the difference calculation does not affect the first value, the other differences are computed as 0.25 - 0 = 0.25 and 1 - 0.25 = 0.75. So we have [ 0 0.25 0.75 ] as the differences. The weights are added cumulatively as before ( 1 + 1 + 1 = 3, 1 + 1 = 2 and 1 on the end stays the same) and thresholded to [ 1 1 1 ] as the final weight vectors. The output is again the sum of the differences multiplied by their respective weights: Output = (1*0) + (1*0.25) + (1*0.75) = 1 = last value in re-ordered inputs = largest/maximum value of input. Hence it is performing the OR function correctly. 'nfa.m' implements the Neuro-Fuzzy AND function and again is similar to the OR program with the signal to be 'AND-ed' the same, p = [1 .25 0], but now the weight vectors are all 1/n where n is the number inputs in this case 3 so the vector of weights is [ 0.333 0.333 0.333 ]. <figure/><quote>>>  Reordered signals and weights: Signals : 0.00 0.25 1.00  Weights : 0.33 0.33 0.33  Difference between neighbouring pairs: 0.00 0.25 0.75  Combined weights: 1.00 0.67 0.33  Thresholded weights: 1 0 0  Output: 0.00 >></quote>This inputs are re-ordered exactly the same as in the OR program. Hence the differences are also the same. The weights are added cumulatively ( 0.333 + 0.333 + 0.333 = 1, 0.333 + 0.333 = 0.667 and 0.333 on the end stays the same as in the original weight vector). These are thresholded (set to 1 if greater than or equal to 1, otherwise set to 0) to [ 1 0 0 ] as the final weight vectors. The output is again the sum of the differences multiplied by their respective weights: Output = (1*0) + (0*0.25) + (0*0.75) = 0. So the output is the first difference = the first entry in the inputs = the smallest input value. Hence it is performing the AND function correctly, since at least one of the inputs is 'low'. <heading>Discussion and conclusions</heading>Maybe look at assignment in context that you are making a proposal to your boss to help him/her make a decision about which of these alternatives to employ to solve a particular problem; for example in the context of your project. So we wish to identify the key factors that are important in a solution based on each of these alternatives in the context of the problem. For example is the problem likely to benefit from learning. If so which type? What are the input/output requirements? Etc. Illustrate, where possible, this with an attempt to implement the selected ISE approach using relevant data; simulated or otherwise. There are advantages and disadvantages of using each approach to Intelligent Systems depending on the intended application. It turns out that Expert Systems are best for representing expert knowledge and knowledge representation. Neural networks such as the supervised and unsupervised examples studied are best for learning, nonlinear and fault tolerant applications. This is because the 'knowledge' that the neural network retains as it learns is spread across the whole network so that an unusual input to one part of it should not affect its ability to provide the correct output. Genetic algorithms are also good for nonlinear problems and have fault tolerance like neural networks. They are best of all though, for fast optimisation. Fuzzy logic is good for anything apart from learning and optimisation. The fact that it was not possible to implement an XNOR solution using fuzzy logic is probably due to not knowing what modifications would be required to the existing programs rather than it not been possible. For the XNOR problem it was found that only expert systems could solve it. The neural nets suffered because it was a non-linearly separable problem. The genetic algorithm could easily be modified using the MLP approach and would totally work for the XNOR problem, this ties in with one of the things they should be good at, that is, solving non-linear problems. The fuzzy approach to the XNOR problem suffered mostly due to a lack of MATLAB programming ability and no clue how to change the programs to simulate an XNOR problem. 