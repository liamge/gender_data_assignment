<abstract>The following paper is a critical review of two research papers, in order to carry this out effectively I will be discussing the strengths and limitations of the research papers with the help of the Critical Appraisal Skills Programme (CASP) guidelines. </abstract><heading>Paper One - Effectiveness of Out-of-home Day Care For Disadvantaged Families: Randomised Controlled Trial</heading><heading>Aim of the study and Research Hypothesis</heading>The main aim of this study was to establish whether providing high quality out-of-home day care has an effect on the health of children from disadvantaged families. This was clearly focused due to: Researchers only assessing the effects of providing day care facilities for young children on the health and welfare of disadvantaged families Population studied consisted of 120 mothers and 143 children (aged between six months and three and a half years) within a catchment area The outcomes remained the same for each family and remained relevant to the above aim The day care that was offered was clearly stated however; the researchers didn't clearly state how they measured the outcomes of the intervention. This is discussed within the critique of the research report. <heading>Critique of the Research Design</heading>Due to the demand for day care places greatly exceeding the number of places available, following a request from the trial team, the borough's education department agreed to use random allocation as a method of rationing places. All the available places were randomly allocated to all the families on the waiting list for the day care centre. The families who previously agreed to take part in the study and were offered a place were then followed up. This enabled allocation of places to all families on the waiting list, not just those taking part in the research. Bowling (1997:54), states that with a Randomised Controlled Trial (RCT): <quote>'Subjects already selected to be rather similar to each other are allocated at random to separate groups; a control group and one or more experimental/treatment group(s) or to two or more groups receiving different interventions' Bowling (1997)</quote>It was evident that this particular study was carried out as an RCT because there was random allocation of participants to an intervention group (families provided with day care facilities) and a control group (families who secured their own child care). The process in which families were allocated to intervention and control groups was computer generated. This was clearly explained within the report. According to Schultz and his colleagues (1995) failure to randomise properly can affect outcome differences between the arms of a trial by up to 40%. It is therefore important that randomisation is carried out properly. Stratification or minimisation can help this. As stated by the researchers minimisation techniques were used to provide a reasonable balance on three potential confounders, these being: <list>Size of familyLone parenthoodWhether application was for a full fee paying or a subsidised place</list>According to Bowling (1997) the above technique helps distribute the characteristics of the subjects evenly across the trial. The researchers however failed to state whether the minimisation was successful and if the groups were well balanced. Yet, there were more families in the control group than in the intervention group (ratio 1:1.4), which could result in inaccurate and unreliable results due to the difference in numbers. Due to influences affecting one arm of the trial more than another, blinding is often necessary, this is where either participants or researchers are unaware of the group they are in, this helps prevent bias and other factors affecting the results. In this study, researchers believed it to be necessary for the paediatrician to be blind, therefore not knowing the child's group status. This was thought to help minimise observer bias; the paediatrician being aware of the child's group status and putting across the pre-conceptions the paediatrician has due to the child's group status. According to Smith (1997), the perceptions and interpretations of researchers are influenced by their preconceptions and experiences. With this particular study at the paediatric assessments some parents talked about their childcare arrangements and so it is not possible to be certain that observer bias didn't occur during the child's assessment. On the whole it is not possible to state if every effort was made to achieve blinding due to this not being stated in the study. It would have been useful if the researchers stated whether all the participants who entered the trial were accounted for at the end and remained in the same group. This would help determine the full effect of the results, due to knowing if the results were a percentage of the original number of participants or the remaining, if the remaining, how many participants this accounted for. Due to this not being stated we can only assume that all participants remained in the same groups until the end of the trial. When the researchers collected the results, the report explains how this was done at the same time on follow up (eighteen months) and the same process was carried out (mothers completed questionnaires on child and family outcomes, paediatricians assessed the child's development). Due to both groups being followed up the same way it is true to say that the researchers are aiming to keep researcher bias to a minimum. In order to recruit a sufficient number of participants to show an effect, researchers calculate how many participants are needed to be reasonably sure of finding significant results. This is known as a power calculation. According to Cohen (1977), power calculations enable the researcher to estimate how large a difference will be observed between the two groups. If a small difference were expected, the sample would need to be large to ensure that the difference will be statistically significant. When the difference is expected to be large, it doesn't take a very large sample to see this difference through statistical analysis. If power calculations aren't used, studies could be based on samples that are too small, this could result in having unsupported hypotheses and rejecting a null hypothesis when it should have been accepted due to either Type I or Type II errors. A Type I error is when the researcher rejects the null hypothesis when it is actually true and a Type II error is when the researcher accepts a null hypothesis that is actually false (LoBiondo-Wood and Haber, 1998). With this study the researchers produced this power calculation based on previous studies. The researchers estimated they would need at least 140 families in order to be able to determine the effect of day care on a child's health, yet only managed to recruit 120 families. As stated earlier this could have resulted in the researchers having unsupported hypotheses, affecting the overall conclusion. <heading>Critique of the Research Report</heading>The researchers have explained all the results by comparing one group against the other, yet not stating if these results are statistically significant. For example: <quote>'At 18 months' follow up, 67% of mothers in the intervention group were in paid work compared with 60% in the control group'</quote>From these findings tables were produced. These showed that even though more mothers in the intervention group were now in paid work, they were however working more hours and less likely to have a household weekly income above Â£200. Researchers also found that children in the intervention group had a slightly higher mean score for mental development, less children had experienced an infection in the previous week, more likely to have otitis media with effusion in one or both ears and more likely to have visited a health practitioner in the previous month. It is however difficult to understand why the above factors that the researchers pointed out are of relevance to the aims of the actual study. The researchers claim these results are imprecise but they don't state why they believe this. Overall from these results you can see that children are no better off health wise with provided day care, however, these results are claimed to be imprecise and so it is very difficult to trust these results. <heading>Practice Implications</heading>From the study it is not justified for any policies or practices to be changed as a result of the evidence contained in this trial for two reasons: The results were imprecise, no true conclusion can be drawn Mothers are the only people who may benefit from more day care to be provided due to enabling them to return to work or studies. However, by providing this day care strictly on this basis you can't guarantee mothers will return to work or studies which will not have a direct effect on children's health, which is the overall aim of the study <heading>Paper Two - Mental Health and Domestic Violence: 'I Call It Symptoms of Abuse'</heading><heading>Aim of the study and Research Hypothesis</heading>' The main aim of this study is to argue the fact that a greater acknowledgement needs to be given to the link between domestic violence and emotional distress; this was clearly stated within the summary. There isn't a specific research question; however it looks into how women with symptoms of abuse are treated and why, resulting in a legitimate research question being brought forward. To meet the aim of the study the researchers laid out two principal secondary aims. Again these were clearly stated and focused. The researcher clearly expressed the importance of this study; convincing the reader it was needed in order to determine how women are treated and whether more concern and thought needs to be brought into this particular care. <heading>Critique of the Research Design</heading>The research was carried out using a qualitative approach to help examine the link between mental health and domestic violence by discussing the experiences of survivors. According to Smith (1997) qualitative research is focused on in-depth studies of human concerns. Opinions, perceptions and feelings of the individual are discussed in order to understand them fully; specific events are observed and analysed for patterns in the data then used as a basis to create theoretical statements; an inductive approach is therefore adopted. This study was carried out using an ethnography approach. Ethnography helps to develop an understanding of culture and patterns of behaviour within groups; the researcher reviews the literature to develop background knowledge of the study and to support future findings (Smith, 1997). This is shown in the literature review, stating the different effects of abuse within different groups (specific countries, wards, ages etc). This method is necessary to obtain sufficient findings and develop an understanding of the possible links between mental health and domestic violence. The researcher hasn't however clearly discussed why the particular research design has been chosen. Instead, stated that the research design is focused on three areas, these being: <list>Women's experiencesChildren's experiencesRole and development of out reach services</list>The researchers clearly stated the research sites and the sample of participants but didn't state why this site would be most suitable for the research and also how and why these participants were chosen; they failed to note the procedure of selection. Having this information would enable us to create an understanding as to how the research was carried out and also build our confidence about the research design enabling us to disregard unethical practice. Where ethical issues are concerned Beauchamp and Childress (1989) believe four main principles need to be considered: <list>Respect for autonomy - respecting people's rights to make decisions based on personal values and beliefs; free from the controlling influence of othersNonmaleficence - not inflicting harmBeneficence - doing or promoting goodJustice - the way individuals are treated relating to their position and worth within a given society</list>By considering all the above principles Smith (1997) believes researchers will be more articulate and confident that they have addressed ethical concerns about the study they are carrying out. We cannot be certain that the above ethical issues were taken into consideration due to the fact that none of the above has been discussed in the research paper and we are unaware as to how participants were screened for entry to the research study, whether consent was gained and whether every effort was made to ensure confidentiality. Therefore we cannot assume this particular study was ethical or unethical due to having no facts to base this statement on, the researchers also failed to clarify whether they received ethical approval for the study. It wasn't clear why the study was conducted the way it was. For example, it was unclear why it was necessary to only interview two women from each of the twelve projects and why more questionnaires were needed. Lengthy questionnaires were produced, with 180 being distributed to project outreach workers and completed by women with their support, except those women who were interviewed, with an average return rate of 80%. The researcher hasn't stated anything about the 20% that refused to complete these questionnaires; we are unaware of the questions that were asked and so can't guarantee that they were unethical or disturbing questions, resulting in the refusal rate. Due to the lack of information in the report about the questionnaires we cannot confidently say that these weren't leading questions (guiding women to answer one way that may not be necessarily true to them), or that it was a valid or reliable questionnaire. The project outreach workers helped women complete the questionnaires, again the researcher failed to explain the environment that this was carried out in or whether they were trained helpers we therefore can't guarantee they didn't affect the answers that the women produced (persuading women to write certain answers and not others). Two women were selected from each of the twelve projects. These women were then interviewed in-depth by the researchers, who again could have an input into the answers the women gave. Again the researchers failed to describe how these interviews were carried out. We can only assume by looking at the results that the questions asked in both the interviews and questionnaires were appropriate due to the researchers retrieving sufficient information from them, as clearly discussed in the findings of the study. In order to establish whether data has been collected in a way that fully addresses the research issue, Gommal. (2000) believes the following issues should be addressed: Respondents briefed about the purpose of the research Information provided about the interviews that might have affected the data produced Information provided about the communicative behaviour between the researcher and respondents If interview respondents reported on what they did or said, whether there were any means of verifying this and were these means used By addressing the above issues it is possible for the researcher to clearly show what the main research issue was, how they went about addressing it and also the information gathered. However, the researcher doesn't state whether any of the above issues were looked at resulting in us being unaware as to whether the research issue was fully addressed and if so, how this truly came about. <heading>Critique of the Research Report</heading>We can only assume the completed questionnaires were analysed inferentially; comparing the responses between participants to look for the most common, due to the only results that are shown are those discussed in detail. We therefore cannot guarantee this was the most effective way to analyse the results. When analysing the interviews it was done on a thematic basis; enabling the researcher to effectively identify themes and analyse the content of each individual theme that arose during the interview. Even though it isn't clearly stated in the report it is possible that the researcher's used content analysis to analyse the responses. Content analysis is the method for the objective, systematic and quantitative description of communications and documentary evidence. It was possible this technique was used due to the researchers having an unstructured response format. Even though this is a logical technique to use and would analyse the results effectively it is only an assumption that this technique has been used, due to the researcher not stating they chose to use this or any other technique to analyse the findings. The findings have been clearly reported and backed up with references from the literature review that was carried out, it is therefore possible that different researchers could interpret the findings differently. Again, it was unclear how these findings came about. Due to the researchers not discussing how these findings came about it is unclear of the credibility of these findings. On the other hand, although not clearly stated by the researchers, they may have carried out a process known as 'triangulation' to help support their findings. Triangulation is a process of combining several lines of sight, enabling the researcher to obtain a better, more substantial picture of reality (Berg, 2001). Triangulation is restricted to the use of multiple data-gathering techniques (usually three) in order to investigate the same phenomenon. By using triangulation in this study, (interviews, questionnaires and previous studies) they were able to provide more support for their findings. Chava Frankfort-Nachmias and David Nachmias (1996) suggests this method helps minimise the degree of specificity of certain methods to particular bodies of knowledge and the hypotheses could be tested in future studies. All the findings are clearly discussed in relation to the original research question, yet only one side of the researcher's argument is discussed; the fact that greater acknowledgement needs to be given to the link between domestic violence and serious emotional distress. This could be due to this being the only side of the argument that was brought about, but by being unaware of the questions asked in both the questionnaires and interviews we cannot be 100% certain that the researchers didn't produce the questions to enable them to define the outcome they wanted to help resolve the above issue. <heading>Practice Implications</heading>From the findings the researchers have clearly linked them to current practice or policies and previous literature. Ways that the research may be used to help women in the future has also been clearly discussed. Yet changing practice or policies due to these findings could be unethical until the researchers have made it clear of the process of obtaining these findings. <heading>Conclusion</heading>Looking back at the first paper it is reasonably clear that providing day care to disadvantaged families would create benefits for the family however, basing changes on this study and this study alone would be insignificant due to the overall results being imprecise. Another study would be needed in order to obtain results that can be trusted. In order to create a better study showing the relevant findings more effort would need to be used to ensure observer bias doesn't take place. It would also be necessary to have a more participants in order to develop a sufficient hypothesis as stated above. As for the second paper it isn't clear that the results could prove strong enough to warrant what the researchers say are the implications for practice, mainly due to the results not being clearly shown and also how these results came about due to the reasons stated earlier. Therefore, this wasn't a very trustworthy study and in order for practice to be changed accordingly it is important that the results are trustworthy. This could be easily overcome by the researches explaining more about how the research was carried out and why. 