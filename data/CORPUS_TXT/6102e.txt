<abstract><heading>ABSTRACT</heading>Flying Brain refers to an Unmanned Aerial Vehicle (UAV), which can remain balance autonomously when encountering unpredictable disturbances. This means that the UAV can regulate its attitude in an environment immediately. Civil and military applications of autonomous flying vehicles have been steadily increasing over the last few years. Traffic surveillance, air pollution monitoring, area mapping, agricultural application, and the remote inspection require high maneuverability and robustness with respect to disturbances [1]. For an UAV, the ability of keeping balance by itself instead of been manipulated by a human can make it more intelligent to meet the requirement of the task. A novel method of using a microcontroller as control centre to process the control loop between a remote controlled helicopter Draganflyer IV （Figure 1.）and a camera based inclinometer sensor will be displayed in this paper. </abstract><heading>INTRODUCTION </heading>Control of UAVs in flight is a large area of interest in current research. For landed system vehicles, only the forward and backward movement associated with the steering control need be considered. Whole the system can be supported into a stationary position by the wheels or some similar stuff. However, for an air dynamic system without ground support, more complicated freedom degrees are on the object. Meanwhile, three rotational axis pitch, roll and yaw are engaged into the movement system. In order to maintain a level hover, UAV need feel the impact which cause the incline in both pitch and roll axis. Inevitably, the vibration from the motor of UAV can not be ignored and it will cause the error when testing incline. To ensure the craft could maintain balance with the unpredictable disturbance, a sensor system need give the feedback to the control centre to support the measurement of incline promptly and accurately. The novel solution to the problem described utilises a vision device coupled spirit vial. The sensors' processor retrieves images from the camera, using them to locate the air bubble within the search environment.[2] This project is partly finished by Chris Vanstone [3], what he has done is that successfully establish a camera based inclinometer. In order to measure the incline of a UAV in both axis to allow autonomous hover, which require a fresh rate of 10Hz or greater, at a resolution of 6' over a ±5°range. The prototype built utilises a small black and white CCD array camera to retrieve images in composite video format which are then analysed in a C++ designed program to locate the bubble position in the dual vial. This inclinometer provided results to indicate that the novel approach could generate measurements with an accuracy and precision sufficient for the application. [2] <figure/>So the sensor's measurement on the vial which indicates the incline can be produced and displayed on the PC. To control the present UAV which has DC motors coupled with four blades, the feedback information from the camera sensor should be converted into the control signal for the motors. When the UAV flying, it need test the level from sensor and analyse the result. However, the information retrieved by the camera attached on the UAV has to be transmitted into a computer (PC), therefore it is not effective enough. Moreover, the UAV has to carry the power and data tethers, which are for camera interfacing with pc, which make the whole device not entirely mobile. To solve this problem, microcontroller can be utilised to be the control centre replacing PC. It is able to receive the information from inclinometer sensor and design a control algorithm to calculate out four different Pulse-Width-Modulations(PWM) that can manipulate four blades to keep a constant attitude of this UAV. Unfortunately, the camera supported is VCM 3612-00 CCD camera that retrieves images in black and white converting them into composite video format. It's hard for microcontroller which can process the data format signal to take in the video signal and analyse it. So the CMUcam (Figure 2.) which is a kind of robot vision sensor is used to substitute for VCM 3612-00. In the following paragraph, a novel approach working with CMUcam and microcontroller for the UAV will be illuminated. <heading>DESIGN</heading>In this project, the CMUcam coupled with the dual vial which is the main component of sensor system and PIC (a kind of microcontroller) with its circuit board are mainly introduced. <picture/><heading>2.1. CMUcam on this project</heading><quote> "CMUcam is a new low-cost, low-power sensor for mobile robots. You can use CMUcam vision system to do many different kinds of on-board, real-time vision processing. Because CMUcam uses a serial port, it can be directly interfaced to other low-power processors such as PIC chips." [5]</quote>Far vital function of CMUcam is that it can be used to track the color. The color blob tracking algorithm allows the user to enter a minimum and maximum threshold for each three RGB or YCrCb channel values, depending on how the camera is set at beginning. Each pixel is compared against the user specified bounds. The best performance of the CMUcam can be achieved when tracking a colored object in the highly contrasting environment. <picture/>CMUcam consists of CMOS camera chip with a built in microcontroller. "A major advantage of CMOS versus CCD camera technology is the ability to integrate additional circuitry on the same die as the sensor itself. This makes it possible to integrate the analog to digital converters and associated pixel grabbing circuitry so a separate frame grabber is not needed".[6] Digital format stream is what is needed. All image data is processed by a high speed, low cost microcontroller which waits for incoming data to stream from the camera and processes it in real time. And then it can output high level information to the outside world via an asynchronous serial interface, so it is easy for CMUcam to communicate to a processor such as PC and any kind of microcontroller. <figure/>To track the position of the air bubble in the vial, after fixing the CMUcam on the above of the dual vial," a dark room" was produced to cover the sensor system. Furthermore, the bubble is illuminated by the light array from the top of the sin bar which is produced to be the stage in experiment. So the "eye sight" of the CMUcam now, is the green vial with a black ring indicating the air bubble. When the sensor which is a part of the UAV is in stationary (balance) position, the black ring should stay at the center of the vial, otherwise the black ring will move around in the vial. So the configuration of the camera at beginning is set to track the green color and then output the center of the vial which is constant data. It is used to compare with the center of the bubble to locate it. Setting the black color for the camera will get the centroid of the bubble. It is easy for the controller to get the error between them. After many experiments the threshold of these two colors is figured out. <table/>When it is tracking, the output from the CMUcam is a data stream at 17 frames per second, which is produced by the camera built in microcontroller. In each data package, only first 2 data is useful for the UAV. They are the centroid of the tracked object. So they need to be stored and calculate the control signal. For an UAV, all the above actions should be implemented automatically by embedded system, so an advanced microcontroller is applied for to process the communication with CMUcam and PWM stuff for the motors. <heading>2.2. Microcontroller </heading>PIC18f458 is selected to process the control actions. "This powerful 10 MIPS (100 nanosecond instruction execution) yet easy-to-program (only 77 single word instructions) CMOS Flash-based 8-bit microcontroller packs Microchip's powerful PIC® architecture with a Controller Area Network (CAN 2.0B) peripheral interface into a 64-pin package and is upwards compatible with the PIC16C5X, PIC12CXXX, PIC16CXX and PIC17CXX devices, providing a seamless migration path of software code to higher levels of hardware integration. The PIC18F6680 features a C compiler-friendly development environment, 1024 bytes of EEPROM, self-programming, an ICD, 2 capture/compare/PWM functions, 12 channels of 10-bit Analog-to-Digital (A/D) converter, 2 comparators, the synchronous serial port can be configured as either 3-wire Serial Peripheral Interface (SPI™) or the 2-wire Inter-Integrated Circuit (I²C™) bus and Addressable Universal Asynchronous Receiver Transmitter (AUSART). All of these features make it ideal for automotive and industrial applications." [6] For the communication, PIC need send the commands to the CMUcam to set it in roll mode and tell it the threshold of color to track the object after giving the power. All commands are sent using visible ASCII characters (123 is 3 bytes "123"). The command which is necessary for the CMUcam is RM and TC. RM is used to engage the raw serial transfer Mode. It reads the bit values of the first 3 (lsb) bits to configure settings. All bits cleared set the default visible ascii mode. If bit 0 is set, then all output from the camera is in raw byte packets. The format of the data packets will be changed so as not to include spaces or be formatted as readable ASCII text. Instead you will receive a 255 valued byte at the beginning of each packet, the packet identifying character (i.e. C for a color packet) and finally the packet. There is no \r sent after each packet, so you must use the 255 to synchronize the incoming data. Any 255 valued bytes that may be sent as part of the packet are set to 254 to avoid confusion. If bit 1 is set, the "ACK\r" and "NCK\r" confirmations are not sent. If bit 3 is set, input will be read as raw byte values, too. [7] The "TC" command begins to track a color. It takes in the minimum and maximum RGB (CrYCb) values and outputs a type M packet in which the first 2 data is the center position needed. If the camera can receive the commands, it will search the object and track it. Then, it outputs the data stream to PIC. When the PIC get the each data packet, it need pick up the first 2 data and then send it out to the control section to analyze the bubble location and calculate out control signal. The communication between PIC and camera is supported by the USART which is used to communicate from the microcontroller to various other devices. The data is changed all the time. It refers that the buffer is refreshed quickly when receives the new data packet, so the register should be set bit by bit for buffer to realize this action. Simultaneously the data should be calculated to get the current position and the movement direction.  FORMULA  are used to constraint the control signal. X and Y are first 2 data in one data stream, which reflects the position of the bubble. △X and △Y are the error between the two near data packet, so it can indicate the direction of movement. If the data received are not in this area, the PWM has to be set to control the DC motors. Draganfly is a novel helicopter which has four blades, so four PWM are needed. However one PIC can only provide two channels PWM from CCP and ECCP respectively, so two PIC s are used in this project. Both two PIC s receive the same digital signal from CMUcam and process exactly same except the PWM stuff. One PIC control 2 motors locating at the same axis with the pre-programmed PWM duty. In each PIC, the CCS which is the compiler used for this project has a special command to set CCP channel PWM, but for ECCP channel, it has to be set bit by bit on ECCP register. <heading>2.3. Dual axis vial spirit </heading>The present vial is a circular dual axis vial measuring 11mm across with the glass plates taking only 6mm of this. The top layer is uniformly curved to produce a 1.5º movement in all directions. This device will show how the dual axis version would work and will give an idea of how good the resolution can get using this method. The vial contains clear Hexane fluid and is transparent on both sides to allow permeation of light. Both of the vials used are manufactured and provided by "Level Developments". [8] <heading>CONCLUSION</heading>The application of CMUcam can make the bubble tracking much easier and it helps calculate out the location of the bubble to share some burdens of PIC. Moreover, it can directly output the digital signal to PIC. From the experiments, it can be seen that the 17 frames per second speed of capture the image is good enough for transmitting movement information of bubble, because when change the level of dual vial, correspondingly the motors speed change swiftly. However, the control algorithm designed in PIC is not optimized, because the finished algorithm can only change the duty of PWM directly to modify the motor speed when the error of location is in the control area without searching the best path to realize the duty change, so for the air system, it is easy to lead the four blades helicopter into pendulum condition. So the genetic algorithm could be introduced into the current programming to optimize the most effective path to generate the four PWM duty changes. 