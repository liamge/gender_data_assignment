<heading>Introduction</heading>A safety-critical or safety-related system comprises everything (hardware, software and human elements) necessary to carry out one or more safety functions, where failure of the safety function would give rise to a significant increase in the risk to the safety of persons and/or the environment. [1] Safety is the freedom from unacceptable risk of physical injury or of damage to the health of people, either directly or indirectly as a result of damage to property or to the environment. [2] A Safety Related System is any system whose malfunction, either directly or indirectly, has the potential to lead to safety being compromised. Within this scope, a Safety-Critical System is defined as: <quote>"A system in which any failure or design error has the potential to lead to loss of life"</quote>Thus a Safety-Critical System presents a direct threat to human life, in the event of a failure. A very small software fault, such as an uninitialised variable in the program, can cascade unto an hazard. <figure/><quote>"Unfortunately, because of the complexity of even simple microcomputer-based systems, it is not possible to demonstrate that a system is correct, or even that it is safe, simply through testing. This places great importance on the development process, which must be directed at the avoidance of design and manufacturing faults."[8]</quote>For this reason the safety critical software development lifecycle is distinctly different from that used for other regular software. Because special consideration to safety is given at all stages of development. <heading>Safety-critical vs. high-availability systems</heading>Many high-availability systems do not threaten human life in cases of failure and instead are designed to maximize uptime and minimize downtime. But safety-critical systems don't always strive to maximize uptime. In fact, they may intentionally take themselves down or bring some subsystems down in situations where there is a threat of injury or loss of life. <figure/><heading>Software safety standards</heading><heading>IEC 61508</heading>IEC 61508 is a generic international standard concerned with the development of systems used to carry out safety functions that incorporate Electrical/Electronic/Programmable Electronic Devices (E/E/PES). It contains explicit requirements and guidelines for the functional safety of safety-related software systems. "All parts of IEC 61508 can be used directly by industry as "stand-alone" publications", but is applicable to other technologies as well. This is because: It covers those aspects that need to be addressed when electrical, electronic and/or programmable electronic systems (E/E/PES) are used to carry out safety functions. It therefore covers not only programmable electronics but also electro-mechanic and solid state electronic systems. Most situations, safety is achieved by a number of protective systems and relies on many technologies (mechanical, hydraulic, pneumatic, electrical, electronic, programmab electronic). Any safety strategy must therefore consider not only all the elements within a individual system (e.g. sensors, control logic and actuators) but also all the safety-relate systems making up the total combination of safety-related systems. Therefore a safety framework within which other technologies can also be addressed is necessary in order that the detailed safety requirements for E/E/PESs can be systematically developed. It is developed in such a way that it can be used as: A basis for the development of other application sector specific standards. An existing standard for application sectors where there is no existing industrty specific standard. Details of IEC 61508 which are specific to individual countries and maintained by professional societies responsible for each country. E.g. "IEE Professional Network: Functional Safety" provides IEC 61508 specific to UK There are two types of safety requirements in IEC 61508: The safety function requirements. They govern the input/output sequences that perform the safety-critical operation. The safety integrity requirements. They are composed of diagnostics and other fail-safe mechanisms used to ensure that failures of the system are detected and that the system goes to a safe state if it's unable to perform a safety function. <heading>IEC 61508 framework:</heading><table/><heading>IEC 61508 compliance software development life cycle</heading>Meeting the requirements of IEC 61508 for software development involves a systematic development process, emphasizing requirements traceability, criticality analysis, and validation. <figure/><table/><heading>IEC 61508 compliance software development process</heading><figure/>For software systems, the standard suggests following a V-model development process. The evolutionary V-model depicts the necessary connection between requirements and validation throughout the entire development process. This version of the V-model recognizes that the development process is not linear and that several iterations of design and implementation may be necessary while end users and developers refine the requirements. Variations of this model are commonly used for non-safety-critical applications; the key differences are the safety-critical requirements. These requirements and their supporting implementation will receive the closest scrutiny during the assessment process. <heading>Hazard analysis</heading>For safety-critical systems, a thorough hazard analysis and risk analysis must be done before architectural design can be done. The objective is to systematically identify the dangers to human safety that a system may pose, including an evaluation of the likelihood of an accident resulting from each hazard. <list><heading>Following are the most common methods:</heading>Hazard and Operability Studies (HAZOP) Event Tree Analysis (ETA)Fault Tree Analysis (FTA)Failure Modes and Effects Analysis (FMEA).Failure Modes, Effects and Criticality Analysis (FMECA)Cause Consequence Analysis (CCA)</list><heading>SIL</heading>The Safety Integrity Level determines the measures that need to be taken against both systematic and random hardware failures in the system. SIL is a quantification of the magnitude of risk reduction. Unlike hardware, software doesn't have well understood general failure-rate analysis mechanisms to determine the SIL for a system. The IEC 61508 standard recognizes this and instead requires different levels of engineering design and practice to ensure the quality of the software in the system. IEC 61508 provides recommendations to the design of the safety-critical system depending on SIL level. E.g. IEC 61508 highly recommends use of limited pointers in programs for SIL4. <table/><list><heading>The most commonly used techniques for assigning target SIL are:</heading>Consequence onlyModified HAZOPRisk MatrixRisk GraphQuantitative AssessmentConsequence Only</list><heading>IEC 61508 language selection requirements </heading>IEC 61508 Part 3 (Software Requirements) provides clearly defined requirements for the software life cycle for "safety-related software" which applies to any software forming part of a safety-related system or used to develop a safety-related system within the scope of IEC 61508-1 and IEC 61508-2. Specific requirements exist for the language selection for development of safety-related software. The following is an abbreviated summary of the relevant requirements for language selection: 7.4.1.3 states, "The third objective of the requirement is to select a suitable set of tools, including languages and compilers for the required safety integrity level, over the whole safety lifecycle of the software which assists verification, validation, assessment and modification" 7.4.2.4 states the language chosen shall possess features that "facilitate software modification such as modularity, information hiding and encapsulation" 7.4.4.2 is essentially a repeat of 7.4.1.3 covering the select of a suitable set of tools but more specifically spells out more detailed categories for use of tools including "automatic testing tools" and specifies the need for these tools to support the entire product lifecycle 7.4.4.3 states the requirements applied to the selection of programming language and calls for the selected language to: "be completely and unambiguously defined or restricted to unambiguously defined features" and "contain features that facilitate the detection of programming mistakes" 7.4.4.4 states that when the preceding requirement cannot be met by the chosen language a further justification is needed which details "the fitness of the language and any additional measures which address any identified shortcomings of the language" <heading>IEC Language selection criteria explained</heading><heading>General language considerations</heading>• Widely used languages or their subsets are preferred to special purpose languages as problems and limitations are more likely to be known. • The language should be user or problem oriented rather than machine oriented. • The language should be completely and unambiguously defined, and in this context a formal definition of the syntax and semantics of the language should exist. • Aspects of languages which cause problems, and are often deemed unsafe, tend to relate to undefined features:- - Ambiguity. - Language features that are unclear or difficult to comprehend. - Features that give rise to different effects depending on the implementation or even the environment. • The possibility of run-time errors is a major source of concern. The occurrence of these and the handling of them are related Program Structure <heading>Program structure requirements</heading><list><heading>• Typical requirements are for:</heading>- Block structured language.- Strongly typed.- Good structuring mechanisms (eg. information hiding).- Safe constructs - no surprises.</list><list><heading>• The language should encourage:</heading>- The use of small and manageable modules.- Restriction of access to data in defined modules.- Definition of variable sub-ranges.- Any other type of error limiting constructs.</list><heading>Language mechanisms support (for)</heading><list>• Fault tolerance.• Mechanisms (such as exceptions, range constraints) to overcome the need for defensive programming etc. • Translation time checking. • Run time type and array bound checking. • Parameter checking. • Assertions, if possible. • Generally maximum amount of support from compilers.</list><heading>Undesirable program design features (that make verification difficult)</heading><list>• Unconditional and conditional jumps excluding subroutine calls (eg. GOTO). • Recursion. • Pointers, heaps or any type of dynamic variables or objects. • Interrupt handling at source code level. • Multiple entries of exits of loops, blocks or subprograms • Implicit variable initialisation or declaration. • Variant records and equivalence.</list>The applicability of program design features depends on the actual SIL level. Following defines the recommends the usage of such features at the appropriate level. <table/><heading>Analysis of programming languages</heading><list><heading>Following table highlights the support for desirables features of:</heading>Assember and it's subset RSRE VISTACAda and it's subsetISO Pascal it's subset SPADE Pascal</list>Subset is a limited feature version of a language where all undesirable functions and features (with regard to safety) have completely removed. <table/><heading>IEC language recommendations</heading>IEC 61508-3 recommends the usage of following languages depending on the SIL level. The following table defines the recommendations. <table/><heading>Quality assurance</heading>Standards and best practise guidance on software development provide a means for consistent, controlled development. Standards can be particularly beneficial in the case of software for Safety-Critical Systems where high levels of safety and reliability must be achieved. Software engineering is a wide-ranging discipline in general requiring expertise in a number of related areas to ensure success. Software quality is of increasing importance as the use of software becomes more pervasive. The Software Engineering Institute (SEI) has developed a Capability Maturity Model (CMM) for assessing an organization's software process capability. The basic premise of CMM is: "The quality of a software system is governed by the quality of the process used to develop and maintain it" <figure/><table/><heading>Testing safety critical systems</heading>The second half of the V-model focuses on verification and validation (testing) at each stage of development. In addition to straightforward requirements validation, developers must perform fault-injection testing at each level as well. Beyond stress testing, fault injection involves disrupting the system to induce a fault and verify that the safety-integrity requirements are met. At the lowest level (unit or module testing), it's important to verify that the module responds appropriately to boundary values and out-of-range values. At this stage, it's especially important to verify that unexpected or uncommon execution paths are handled correctly. For example, verify that your CRC routine can indeed detect multiple-bit faults and out-of-order sequence faults. As you integrate software (and hardware) modules, you must conduct further testing to verify their interaction and show that interfaces are operating as specified. Fault injections at this level might verify that one module responds properly when a second module rejects its input. This is also the stage at which you should validate diagnostics and monitoring software. At the highest level, the system-validation plan must completely test each safety function and safety-integrity requirement. System-level validation should take place in as "life-like" an environment as possible. Here, fault injection can come in the form of communications faults or jabber, input loading, power, and environmental faults. <heading>Formal methods</heading>Formal methods are use of mathematical notations to describe systems. They are very highly reliable and dependable because they can "prove program behavior correctness using logic and mathematics" [12] and absolute proof can be given since it's based on maths. <quote>"However the industry has been understandably reluctant to use formal methods since they have largely been untried in practice. There are many methods being touched around the market place and formal methods are just one form of them. When trying out any of these new techniques for formal methods in particular, few engineers, programmers and managers currently have the skills to apply the techniques beneficially (although many have the ability)the first time, the cost of failure could be prohibitive and the initial cost of training is likely to be very high. For formal methods in particular, few engineers, programmers and managers currently have the skills to apply the techniques beneficially (although many have the ability)." [9]</quote>Another major barrier in acceptance of formal methods is that many engineers and programmers do not have the appropriate training to make use of them and many managers do not know when and how they can be applied. However this is gradually alleviated as: Necessary mathematics and formal methods is being taught now in the universities. New standards and drafts have begun to include formal methods for safety critical systems. <quote>"Government legislation is likely to provide increasing motivation to apply appropriate techniques in the development of safety critical systems." [9]</quote>The use of formal methods in the future in the safety critical systems is very promising. <heading>Safety Critical Software license in the UK</heading><quote>"Before any organization can operate a life-critical computer system it must first obtain a License To Operate (LTO), which will only be issued when the operator can demonstrate that certain conditions (detailed below) have been met." [10]</quote><quote>"Each life-critical system must be operated by a Certified Software Engineer who is named as being personally responsible for the system. This Certified Software Engineer must have received the appropriate mathematical training in safety-critical software engineering. " [10]</quote><quote>"A life-critical system must be adequately maintained; this must be one of the conditions of the LTO. Maintenance (that is, rectification and development) must be the responsibility of a named Certified Software Engineer. " [10]</quote><quote>"An LTO must only be granted when a Safety Certificate has been issued. Certificates must be issued for limited periods, for example, five years. Operational systems will thus need to be recertificated (relicensed) periodically (analogous to Certificate of Airworthiness). " [10]</quote><heading>Legal issues</heading>An issue which should exercise the mind of any supplier of a critical system is the question of exposure in law should the system fail. <heading>Liability</heading><quote>"Civil liability for a defective system can arise under the laws of contract, misrepresentation, tort, other common law doctrines and under current UK legislation. Furthermore, European Directives impact upon UK legislation and will continue to do so. Liability can fall on the manufacturer, supplier, distributor or certifier of products. In practice, such a supplier or manufacturer is a company and is regarded as a legal entity who can sue or can be sued in its own right. Suppliers of components can also be liable. In cases where the component is used in products which are exposed to the general public the extent of such liability can be enormous." [5]</quote><quote>"Under legislation which regulates the "sale of goods" and "supply of services" and which invariably applies to the supply of hardware and software, there are terms implied into the supply contract. Most important of the provisions are under sections 13 and 14 of the Sale of Goods Act 1979 as amended by the Sale of Goods (Amendments) Act 1994 (and the equivalent sections 8 and 9 of the Supply of Goods and Services Act 1982). " [5]</quote><quote>"Section 13 states that the goods supplied must correspond with their description. If a computer system has a description that it will "perform X number of functions per second" or that the software complies with specified standards, the supplier will be in breach of this implied term if the system or software is not as described. " [5]</quote><quote>"Section 14 states that the goods must be of satisfactory quality and that they are reasonably fit for the buyer's purpose. The second limb of this implied term operates where the buyer expressly or by implication makes known to the supplier any particular purpose for which the goods are being bought (whether or not that purpose is one for which the goods are commonly supplied). In many circumstances, such as in the supply of safety-critical systems, the purpose arises by implication. In circumstances where it would be unreasonable for the buyer to rely on the skill and judgement of the seller, or he did not in fact rely on the seller's skill, then this term is not implied. In the safety-related field it is also likely that a particular purpose will be expressly stated. " [5]</quote><quote>"Certain clauses ('exclusion clauses') are commonly relied on to exclude or restrict the liability of a party arising through the failure to perform a contract. The Unfair Contract Terms Act 1977 limits this ability to exclude or restrict liability in certain contracts. In particular, it is never possible to exclude or restrict liability in negligence, or in relation to failure to take reasonable care in the performance of a contract, for personal injury or death by reference to any contract term . " [5]</quote><quote>"The legislation places the burden of proof on the defendant and so it is for the producer to prove that it is impossible to discover the defect. From a practical point of view, manufacturers and suppliers of computer hardware and software must take notice of (and comply with) those standards which do exist in the computer industry. Similarly, manufacturers should ensure that adequate verification and validation procedures in the production of software are followed. They should also take note of any other procedures and draft standards generally followed by cautious manufacturers. Such actions would be seen as evidence in support of this defence, although would not necessarily absolve the defendant from liability. " [5]</quote><heading>Tort</heading><quote>"A contract sets the parameters of liability, and the rules of privity (ie. only a party to the contract is able to sue) limit the persons who can claim for loss or damage under a contract. Where, however, a duty of care can be established between a person who has manufactured or supplied a product and the person injured then this injured party may be able to sue in tort for the negligence of the manufacturer or supplier. Tort means simply a legal "wrong" and more particularly a civil wrong as opposed to a criminal offence. " [5]</quote><quote>"For a duty of care to exist it must be reasonably foreseeable that in the absence of reasonable care in the preparation of a product the consumer (or the innocent by-stander) may suffer injury to his (or her) life or property. This duty will occur when the product is intended to reach the ultimate consumer in the state in which it left the manufacturer. In practice, it is not usually difficult to find one or more persons who owe a duty of care in the circumstances of the supply of a safety-critical system. " [5]</quote><heading>Consumer Protection Act</heading><quote>"Only damage of a specific type may form the basis of an action under the Consumer Protection Act. The damage may be death, personal injury or damage to property. However, only property which is of a type ordinarily intended for private use may be the subject of a claim and property damage must exceed £275. Therefore, if a chemical plant was to explode because of a faulty computer control system the damage to any surrounding office buildings or to the chemical plant itself could not be the subject of a claim under the Act. Office buildings are not ordinarily intended for private use. However, if the homes or possessions of nearby individuals were also damaged, liability to pay compensation would arise for the damage to those houses and possessions under the Consumer Protection Act. " [5]</quote><quote>"A plaintiff who brings an action under the Consumer Protection Act must show that, as a result of the defect in the product, it was reasonably foreseeable that an injury of the type suffered would occur. This is unlikely to be difficult in the context of a safety-critical system: if it is not safe, it is reasonably foreseeable that persons will be injured and property damaged as a result. " [5]</quote><quote>"The practical scope for a manufacturer or supplier to exclude or restrict his liability under the Consumer Protection Act is very limited. " [5]</quote>